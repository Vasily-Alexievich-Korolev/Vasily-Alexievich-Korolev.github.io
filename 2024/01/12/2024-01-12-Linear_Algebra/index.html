<!DOCTYPE html>
<html>
<head>
  <meta charset="utf-8">
  
  
  <title>2024-01-12-Linear_Algebra | 主标题</title>
  <meta name="viewport" content="width=device-width, initial-scale=1, shrink-to-fit=no">
  <meta name="description" content="求解线性方程组使用矩阵消元摘要 用于消元的矩阵有两种：消元矩阵$E_{ij}$和交换矩阵$P_{ij}$  消元矩阵$E_{ij}$是将单位矩阵$I$的$a_{ij}$换为$-l$，其中$l &#x3D; \dfrac{a_{ij}}{a_{ii}}$  交换矩阵$P_{ij}$是将单位矩阵$I$中的第$i$行和第$j$列交换得到的矩阵   矩阵的LU分解摘要 通过将$E_{ij}$求逆可以得到$">
<meta property="og:type" content="article">
<meta property="og:title" content="2024-01-12-Linear_Algebra">
<meta property="og:url" content="https://vasily-alexievich-korolev.github.io/2024/01/12/2024-01-12-Linear_Algebra/index.html">
<meta property="og:site_name" content="主标题">
<meta property="og:description" content="求解线性方程组使用矩阵消元摘要 用于消元的矩阵有两种：消元矩阵$E_{ij}$和交换矩阵$P_{ij}$  消元矩阵$E_{ij}$是将单位矩阵$I$的$a_{ij}$换为$-l$，其中$l &#x3D; \dfrac{a_{ij}}{a_{ii}}$  交换矩阵$P_{ij}$是将单位矩阵$I$中的第$i$行和第$j$列交换得到的矩阵   矩阵的LU分解摘要 通过将$E_{ij}$求逆可以得到$">
<meta property="og:locale" content="zh_CN">
<meta property="article:published_time" content="2024-01-11T19:20:16.000Z">
<meta property="article:modified_time" content="2024-01-11T19:22:51.823Z">
<meta property="article:author" content="Vasily Alexievich Korolev">
<meta property="article:tag" content="关键词">
<meta name="twitter:card" content="summary">
  
    <link rel="alternate" href="/atom.xml" title="主标题" type="application/atom+xml">
  
  
    <link rel="shortcut icon" href="/favicon.png">
  
  
  
<link rel="stylesheet" href="/css/style.css">

  
    
<link rel="stylesheet" href="/fancybox/jquery.fancybox.min.css">

  
  
<meta name="generator" content="Hexo 7.0.0"></head>

<body>
  <div id="container">
    <div id="wrap">
      <header id="header">
  <div id="banner"></div>
  <div id="header-outer" class="outer">
    <div id="header-title" class="inner">
      <h1 id="logo-wrap">
        <a href="/" id="logo">主标题</a>
      </h1>
      
        <h2 id="subtitle-wrap">
          <a href="/" id="subtitle">副标题</a>
        </h2>
      
    </div>
    <div id="header-inner" class="inner">
      <nav id="main-nav">
        <a id="main-nav-toggle" class="nav-icon"><span class="fa fa-bars"></span></a>
        
          <a class="main-nav-link" href="/">Home</a>
        
          <a class="main-nav-link" href="/archives">Archives</a>
        
      </nav>
      <nav id="sub-nav">
        
        
          <a class="nav-icon" href="/atom.xml" title="RSS 订阅"><span class="fa fa-rss"></span></a>
        
        <a class="nav-icon nav-search-btn" title="搜索"><span class="fa fa-search"></span></a>
      </nav>
      <div id="search-form-wrap">
        <form action="//google.com/search" method="get" accept-charset="UTF-8" class="search-form"><input type="search" name="q" class="search-form-input" placeholder="搜索"><button type="submit" class="search-form-submit">&#xF002;</button><input type="hidden" name="sitesearch" value="https://vasily-alexievich-korolev.github.io"></form>
      </div>
    </div>
  </div>
</header>

      <div class="outer">
        <section id="main"><article id="post-2024-01-12-Linear_Algebra" class="h-entry article article-type-post" itemprop="blogPost" itemscope itemtype="https://schema.org/BlogPosting">
  <div class="article-meta">
    <a href="/2024/01/12/2024-01-12-Linear_Algebra/" class="article-date">
  <time class="dt-published" datetime="2024-01-11T19:20:16.000Z" itemprop="datePublished">2024-01-12</time>
</a>
    
  </div>
  <div class="article-inner">
    
    
      <header class="article-header">
        
  
    <h1 class="p-name article-title" itemprop="headline name">
      2024-01-12-Linear_Algebra
    </h1>
  

      </header>
    
    <div class="e-content article-entry" itemprop="articleBody">
      
        <h1 id="求解线性方程组"><a href="#求解线性方程组" class="headerlink" title="求解线性方程组"></a>求解线性方程组</h1><h2 id="使用矩阵消元"><a href="#使用矩阵消元" class="headerlink" title="使用矩阵消元"></a>使用矩阵消元</h2><h3 id="摘要"><a href="#摘要" class="headerlink" title="摘要"></a>摘要</h3><ol>
<li><p>用于消元的矩阵有两种：消元矩阵$E_{ij}$和交换矩阵$P_{ij}$</p>
</li>
<li><p>消元矩阵$E_{ij}$是将单位矩阵$I$的$a_{ij}$换为$-l$，其中$l &#x3D; \dfrac{a_{ij}}{a_{ii}}$</p>
</li>
<li><p>交换矩阵$P_{ij}$是将单位矩阵$I$中的第$i$行和第$j$列交换得到的矩阵</p>
</li>
</ol>
<h2 id="矩阵的LU分解"><a href="#矩阵的LU分解" class="headerlink" title="矩阵的LU分解"></a>矩阵的LU分解</h2><h3 id="摘要-1"><a href="#摘要-1" class="headerlink" title="摘要"></a>摘要</h3><ol>
<li><p>通过将$E_{ij}$求逆可以得到$L_{ij}$。其中，$L_{ij}$中除了主对角线，所有元素变为原来的相反数。</p>
</li>
<li><p>$A &#x3D; LU$分解得到的两个矩阵$L$和$U$分别为下三角形矩阵和上三角形矩阵。</p>
</li>
<li><p>通过$A &#x3D; LU$求解方程组$A\boldsymbol{x} &#x3D; \boldsymbol{b}$的方法：</p>
<ol>
<li><p>执行$A &#x3D; LU$分解，得到$L$和$U$</p>
</li>
<li><p>求解$L\boldsymbol{c} &#x3D; \boldsymbol{b}$，然后求解$U\boldsymbol{x} &#x3D; \boldsymbol{c}$</p>
</li>
</ol>
</li>
<li><p>$A &#x3D; LU$可以写为$A &#x3D; LDU$，其中$D$为主对角线与原来的$U$相同，其他元素为0。而此时$U$的主对角线为1，其他元素为$\dfrac{u_{ij}}{d_{i}}$</p>
</li>
</ol>
<h2 id="转置和交换"><a href="#转置和交换" class="headerlink" title="转置和交换"></a>转置和交换</h2><h3 id="摘要-2"><a href="#摘要-2" class="headerlink" title="摘要"></a>摘要</h3><ol>
<li><p>$AB$和$A^{-1}$的转置分别为$B^{\mathrm{T}} A^{\mathrm{T}}$和$(A^{\mathrm{T}})^{-1}$</p>
</li>
<li><p>$\boldsymbol{x}$和$\boldsymbol{y}$的内积为$\boldsymbol{x}^{\mathrm{T}}\boldsymbol{y}$；外积为$\boldsymbol{x}\boldsymbol{y}^{\mathrm{T}}$</p>
</li>
<li><p>对称矩阵（symmetric matrix）满足$S^{\mathrm{T}} &#x3D; S$</p>
</li>
<li><p>正交矩阵（orthogonal matrix）满足$Q^{\mathrm{T}} &#x3D; Q^{-1}$。$Q$的列均为正交单位向量。</p>
</li>
<li><p>交换矩阵（Permutaiton matrix）$P$为单位矩阵的行按照任意顺序排列得到的矩阵。$P$有$n!$种排列，且$P^{\mathrm{T}} &#x3D; P^{-1}$</p>
</li>
</ol>
<h3 id="PA-LU"><a href="#PA-LU" class="headerlink" title="PA &#x3D; LU"></a>PA &#x3D; LU</h3><p>有时为了满足阶梯型矩阵，需要进行行交换操作。因此，此时进行LU分解得到如下的表达式<br>$$<br>A &#x3D; E_{ij}^{-1}\dots P_{lm}^{-1} \dots E_{pq}^{-1}U<br>$$</p>
<p>我们一般选择先进行交换，再进行消元，因此$A &#x3D; LU$可以扩写为<br>$$<br>PA &#x3D; LU<br>$$</p>
<h3 id="求导的转置"><a href="#求导的转置" class="headerlink" title="求导的转置"></a>求导的转置</h3><p>我们已经知道，两个向量的内积可以表示为<br>$$<br>\boldsymbol{x}\cdot \boldsymbol{y} &#x3D; \boldsymbol{x}^{\mathrm{T}} \boldsymbol{y} &#x3D; \sum\limits_{i &#x3D; 1}^{n} x_{i}y_{i}<br>$$<br>如果我们现在求两个函数的内积，那么不难推广得到<br>$$<br>\boldsymbol{x}^{\mathrm{T}} \boldsymbol{y} &#x3D; \int_{-\infty}^{\infty}x(t)y(t)\mathrm{d} t<br>$$<br>假设$A &#x3D; \dfrac{\mathrm{d}}{\mathrm{d} t}$，那么将其代入内积可得<br>$$<br>\int_{-\infty}^{\infty} \dfrac{\mathrm{d} x(t)}{\mathrm{d} t} y(t) \mathrm{d} t &#x3D; \int_{-\infty}^{\infty} x(t) \left( -\dfrac{\mathrm{d} y}{\mathrm{d} t} \right) \mathrm{d} t<br>$$<br>这表明，如果我们认为此时内积满足$(A\boldsymbol{x})^{\mathrm{T}} \boldsymbol{y} &#x3D; \boldsymbol{x}^{\mathrm{T}} (A^{\mathrm{T}}\boldsymbol{y})$，那么就会得到<br>$$<br>A^{\mathrm{T}} &#x3D; -\dfrac{\mathrm{d}}{\mathrm{d} t}<br>$$</p>
<h1 id="向量空间和子空间"><a href="#向量空间和子空间" class="headerlink" title="向量空间和子空间"></a>向量空间和子空间</h1><h2 id="向量空间"><a href="#向量空间" class="headerlink" title="向量空间"></a>向量空间</h2><h3 id="摘要-3"><a href="#摘要-3" class="headerlink" title="摘要"></a>摘要</h3><ol>
<li><p>标准的$n$维空间$\boldsymbol{R}^{n}$包含了所有含有$n$个参数的实向量。</p>
</li>
<li><p>如果向量$\boldsymbol{v}, \boldsymbol{w} \in \boldsymbol{S}$，那么$c\boldsymbol{v} + d\boldsymbol{w} \in S$</p>
</li>
<li><p>$\boldsymbol{R}^{n}$的子空间是$\boldsymbol{R}^{n}$内的一个向量空间。</p>
</li>
<li><p>$A$的列空间为$A$的所有列向量的线性组合。如果$A$为$m\times n$矩阵，那么$A$的列空间为$\boldsymbol{R}^{m}$的子空间。</p>
</li>
<li><p>$A\boldsymbol{x} &#x3D; \boldsymbol{b}$可解等价于$\boldsymbol{b} \in \boldsymbol{C}(A)$（$\boldsymbol{C}(A)$为$A$的列空间）。</p>
</li>
</ol>
<h3 id="向量空间的定义"><a href="#向量空间的定义" class="headerlink" title="向量空间的定义"></a>向量空间的定义</h3><h4 id="特殊的向量空间"><a href="#特殊的向量空间" class="headerlink" title="特殊的向量空间"></a>特殊的向量空间</h4><ol>
<li><p>$\boldsymbol{M}$：包含所有$2\times2$矩阵的空间</p>
</li>
<li><p>$\boldsymbol{F}$：包含所有实函数$f(x)$的空间</p>
</li>
<li><p>$\boldsymbol{Z}$：仅包含零向量的空间</p>
</li>
<li><p>$\boldsymbol{P}_{n}$：包含所有的$n$阶多项式</p>
</li>
</ol>
<h3 id="A-的列空间"><a href="#A-的列空间" class="headerlink" title="$A$的列空间"></a>$A$的列空间</h3><h4 id="列空间"><a href="#列空间" class="headerlink" title="列空间"></a>列空间</h4><p>对于$m \times n$矩阵$A$，其列空间为$\boldsymbol{R}^{m}$的子空间。</p>
<h4 id="向量组张成空间"><a href="#向量组张成空间" class="headerlink" title="向量组张成空间"></a>向量组张成空间</h4><p>对于任意一个向量空间$\boldsymbol{V}$，假设其中有一些向量组成了如下集合<br>$$<br>S &#x3D; {\boldsymbol{v}<em>{1}, \boldsymbol{v}</em>{2}, \dots, \boldsymbol{v}<em>{N}} \boldsymbol{v}</em>{i} \in \boldsymbol{V}<br>$$<br>对于一般情况，这个集合并不是子空间。然而，这些向量的所有线性组合均存在于$\boldsymbol{V}$中。因此，我们可以得到由这些向量线性组合得到的空间是$\boldsymbol{V}$的子空间。我们将其称为向量组$S$张成的空间。</p>
<h2 id="矩阵-A-的零空间：求解-A-boldsymbol-x-0-以及-R-boldsymbol-x-0"><a href="#矩阵-A-的零空间：求解-A-boldsymbol-x-0-以及-R-boldsymbol-x-0" class="headerlink" title="矩阵$A$的零空间：求解$A\boldsymbol{x} &#x3D; 0$以及$R\boldsymbol{x} &#x3D; 0$"></a>矩阵$A$的零空间：求解$A\boldsymbol{x} &#x3D; 0$以及$R\boldsymbol{x} &#x3D; 0$</h2><h3 id="摘要-4"><a href="#摘要-4" class="headerlink" title="摘要"></a>摘要</h3><ol>
<li><p>零空间$\boldsymbol{N}(A)$包含了$A\boldsymbol{x} &#x3D; 0$的所有解$\boldsymbol{x}$</p>
</li>
<li><p>上阶梯型矩阵可以化为主元均为1，且主元所在列的其他元素均为0的简化阶梯型矩阵$R &#x3D; \mathrm{rref}(A)$（书中称其为redoced row echelon form）。</p>
</li>
<li><p>从$A$向$R$转化的过程中零空间不变。</p>
</li>
<li><p>如果矩阵$A$的第$j$列没有主元，那么此列对应的变量$x_{j}$为自由变量，此列为自由列。当$x_{j} &#x3D; 1$时，$A\boldsymbol{x} &#x3D; 0$有特解。</p>
</li>
<li><p>主元的数量与$R$中非零行的数量相等，我们将其称为$R$的秩，记为$\mathrm{rank}R &#x3D; r$。同时，$R$有$n - r$个自由列。</p>
</li>
<li><p>对$m \times n$矩阵$A$，如果$m &lt; n$，那么其零空间内有非零解。</p>
</li>
</ol>
<h3 id="引入"><a href="#引入" class="headerlink" title="引入"></a>引入</h3><p>$A$的零空间包含了所有满足$A\boldsymbol{x} &#x3D; 0$的特解的线性组合。</p>
<h3 id="简化行阶梯矩阵-R"><a href="#简化行阶梯矩阵-R" class="headerlink" title="简化行阶梯矩阵$R$"></a>简化行阶梯矩阵$R$</h3><p>对于$m \times n$矩阵$A$，其零空间为$\boldsymbol{R}^{n}$的子空间。</p>
<h3 id="矩阵的秩"><a href="#矩阵的秩" class="headerlink" title="矩阵的秩"></a>矩阵的秩</h3><p>下面的例子是秩为1的情况<br>$$<br>A &#x3D; \begin{bmatrix}<br>1 &amp; 3 &amp; 10 \<br>2 &amp; 6 &amp; 20 \<br>3 &amp; 9 &amp; 30 \<br>\end{bmatrix} \longrightarrow<br>R &#x3D; \begin{bmatrix}<br>1 &amp; 3 &amp; 10 \<br>0 &amp; 0 &amp; 0 \<br>0 &amp; 0 &amp; 0 \<br>\end{bmatrix}<br>$$<br>不难看出，矩阵$A$中的第二列和第三列均为第一列的倍数。因此，如果我们假设$\boldsymbol{u} &#x3D; [1\ 2\ 3]^{\mathrm{T}}$，那么我们可以按照如下方式变形<br>$$<br>A &#x3D; [\boldsymbol{u}\ 3\boldsymbol{u}\ 10\boldsymbol{u}] &#x3D; \boldsymbol{u}[1\ 3\ 10]<br>$$<br>假设$\boldsymbol{v} &#x3D; [1\ 3\ 10]^{\mathrm{T}}$，那么$A &#x3D; \boldsymbol{u}\boldsymbol{v}^{\mathrm{T}}$。将其代入$A\boldsymbol{x} &#x3D; 0$，我们可以得到$\boldsymbol{u}(\boldsymbol{v}^{\mathrm{T}}\boldsymbol{x}) &#x3D; 0$。这样我们可以得到$\boldsymbol{v}^{\mathrm{T}}\boldsymbol{x} &#x3D; 0$。换言之，对于秩为1的情况<br>$$<br>\forall \boldsymbol{x} \in \boldsymbol{N}(A),\ \exists \boldsymbol{v} \in \boldsymbol{C}(A),\ \boldsymbol{v}^{\mathrm{T}}\boldsymbol{x} &#x3D; 0<br>$$<br>这表明列空间中的向量与零空间中的向量正交。</p>
<h2 id="A-boldsymbol-x-boldsymbol-b-的通解"><a href="#A-boldsymbol-x-boldsymbol-b-的通解" class="headerlink" title="$A\boldsymbol{x} &#x3D; \boldsymbol{b}$的通解"></a>$A\boldsymbol{x} &#x3D; \boldsymbol{b}$的通解</h2><h3 id="摘要-5"><a href="#摘要-5" class="headerlink" title="摘要"></a>摘要</h3><ol>
<li><p>$A\boldsymbol{x} &#x3D; \boldsymbol{b}$的通解为$A\boldsymbol{x} &#x3D; 0$的通解$\boldsymbol{x}<em>{n}$与$A\boldsymbol{x} &#x3D; \boldsymbol{b}$的特解$\boldsymbol{x}</em>{p}$之和$\boldsymbol{x}<em>{n} + \boldsymbol{x}</em>{p}$</p>
</li>
<li><p>当$m\times n$矩阵$A$列满秩时，矩阵$A$变形生成的矩阵$R$没有自由列。这意味着$\boldsymbol{N}(A) &#x3D; \boldsymbol{Z}$。</p>
</li>
<li><p>当$m\times n$矩阵$A$列满秩时，$\boldsymbol{C}(A) &#x3D; \boldsymbol{R}^{m}$。这意味着$A\boldsymbol{x} &#x3D; \boldsymbol{b}$总是有解。</p>
</li>
<li><p>当$m\times n$矩阵$A$同时行满秩和列满秩时，矩阵$A$可逆。</p>
</li>
</ol>
<h3 id="A-boldsymbol-x-p-boldsymbol-b-的一个特解"><a href="#A-boldsymbol-x-p-boldsymbol-b-的一个特解" class="headerlink" title="$A\boldsymbol{x}_{p} &#x3D; \boldsymbol{b}$的一个特解"></a>$A\boldsymbol{x}_{p} &#x3D; \boldsymbol{b}$的一个特解</h3><p>当列满秩时，矩阵$A$的列数与主元数相同，这意味着$R$没有自由列。因此，此时$R$可以按照分块矩阵写为<br>$$<br>R &#x3D; \begin{bmatrix}<br>I\<br>0\<br>\end{bmatrix}<br>$$<br>其中，上半部分为$n\times n$的单位矩阵，下半部分为$(m - n)\times n$的零矩阵。同时，没有自由列意味着$\boldsymbol{N}(A) &#x3D; \boldsymbol{Z}$，或者说$\boldsymbol{x}_{n} &#x3D; 0$。如果我们将其代入通解，可以得到这样的结论：如果$A\boldsymbol{x} &#x3D; \boldsymbol{b}$有解，那么其只有一个解。用下一章的话讲，此时$A$的列线性无关。</p>
<h3 id="通解"><a href="#通解" class="headerlink" title="通解"></a>通解</h3><p>行满秩意味着每一行都有主元。这说明每一行都是线性无关的。如果这个空间内有$m$个线性无关的向量，那么显然这个空间是$m$维的。这也就是说，$C(A) &#x3D; \boldsymbol{R}^{m}$。</p>
<p>我们可以认为每一个满足$n$元一次方程的点，都在该方程所规定的比原空间维度低一维的空间内。这样，我们可以认为$A\boldsymbol{x} &#x3D; 0$的零空间意味着满足某一系列约束条件的点的集合（或者说是在“广义平面”的公共部分的向量集合，这个集合显然构成一个向量空间，也就是零空间）。同时，我们需要注意这样的集合包括原点。</p>
<p>现在，如果我们将$A\boldsymbol{x}<em>{n}$改为$A(\boldsymbol{x}</em>{n} + \boldsymbol{x}<em>{p})$，那么实际上是将每个向量按照$\boldsymbol{x}</em>{p}$的方向平移。显然，有许多种平移方法可以得到相同的结果，而我们只需要一种平移方法即可。同时，由于并没有规定如何按照$\boldsymbol{x}_{p}$平移，因此对于所有的$\boldsymbol{b}$，总能找到一个对应的平移方法。这也就是说，对于任意的$\boldsymbol{b}$，$A\boldsymbol{x} &#x3D; \boldsymbol{b}$总是有解。</p>
<h2 id="线性无关、基向量和维数"><a href="#线性无关、基向量和维数" class="headerlink" title="线性无关、基向量和维数"></a>线性无关、基向量和维数</h2><h3 id="摘要-6"><a href="#摘要-6" class="headerlink" title="摘要"></a>摘要</h3><ol>
<li><p>如果$A$的列向量线性无关，那么$A\boldsymbol{x} &#x3D; 0$的唯一解为$\boldsymbol{x} &#x3D; 0$，$A$的零空间为$\boldsymbol{Z}$</p>
</li>
<li><p>如果一组向量$\boldsymbol{v}<em>{i}(i &#x3D; 1\dots k)$线性无关，那么只有当所有$c</em>{i} &#x3D; 0$时才有$\sum\limits_{i &#x3D; 1}^{n} c_{i}\boldsymbol{v}_{i} &#x3D; 0$。</p>
</li>
<li><p>当$m &lt; n$时，矩阵有线性相关列，并且矩阵至少有$n - m$自由变量。</p>
</li>
<li><p>在由一组向量$\boldsymbol{v}<em>{i}(i &#x3D; 1\dots k)$张成的空间$\boldsymbol{S}$中，任意一个向量均可表示为$\boldsymbol{v}</em>{i}(i &#x3D; 1\dots k)$的线性组合</p>
</li>
<li><p>一组向量$\boldsymbol{v}_{i}(i &#x3D; 1\dots k)$是空间$\boldsymbol{S}$的基向量的充要条件为这一组向量张成这个空间，且这一组向量线性无关。</p>
</li>
<li><p>向量空间$\boldsymbol{S}$的维数为向量空间中基向量的个数</p>
</li>
</ol>
<h3 id="引入-1"><a href="#引入-1" class="headerlink" title="引入"></a>引入</h3><p>基向量组是张成向量空间的线性无关向量组。每一个空间中的向量都可以表示为基向量组的唯一一种线性组合。下面是四个重要的概念以及其含义：</p>
<ol>
<li><p>线性无关向量组：没有额外的向量</p>
</li>
<li><p>张成空间的向量组：具有足够的向量，从而通过线性组合产生其他向量</p>
</li>
<li><p>空间的基：张成空间的最小向量组（不多也不少）</p>
</li>
<li><p>空间的维数：基中向量个数</p>
</li>
</ol>
<h3 id="线性无关"><a href="#线性无关" class="headerlink" title="线性无关"></a>线性无关</h3><p>以下几个概念等价：</p>
<ol>
<li><p>$m \times n$矩阵$A$列满秩 </p>
</li>
<li><p>$\mathrm{rank}A &#x3D; n$</p>
</li>
<li><p>$m \times n$矩阵$A$有$n$个主元</p>
</li>
<li><p>$\boldsymbol{N}(A)$中只有$\boldsymbol{x} &#x3D; 0$</p>
</li>
</ol>
<h3 id="张成一个子空间的向量组"><a href="#张成一个子空间的向量组" class="headerlink" title="张成一个子空间的向量组"></a>张成一个子空间的向量组</h3><p>我们将$m\times n$矩阵$A$的行空间定义为由矩阵中行向量所张成的$\boldsymbol{R}^{n}$的子空间，记为$\boldsymbol{C}(A^{\mathrm{T}})$</p>
<h3 id="向量空间的基"><a href="#向量空间的基" class="headerlink" title="向量空间的基"></a>向量空间的基</h3><p>向量空间的基是满足如下条件的一组向量：</p>
<ol>
<li><p>基向量线性无关</p>
</li>
<li><p>基向量能张成线性空间</p>
</li>
</ol>
<p>对于每个在向量空间的向量，其仅有一种表示为基向量线性组合的方式。</p>
<p>$n$阶单位矩阵的列向量为$\boldsymbol{R}^{n}$的标准基。</p>
<p>当$A$可逆时，对$A\boldsymbol{x} &#x3D; 0$显然可以两边同时左乘$A^{-1}$，这样可以得到$\boldsymbol{x} &#x3D; 0$。这表明，当$A$可逆时，$\boldsymbol{C}(A) &#x3D; \boldsymbol{Z}$，因此我们可以得到，可逆矩阵的列向量线性无关。同时，由于对$A\boldsymbol{x} &#x3D; \boldsymbol{b}$，我们总是可以得到$\boldsymbol{x} &#x3D; A^{-1}\boldsymbol{b}$，因此当$A$可逆时，其列向量为$\boldsymbol{R}^{n}$的一组基。同样，我们还可以得到，由于可逆矩阵的组成方式有无限多种，因此$\boldsymbol{R}^{n}$的基的数量也无限多。</p>
<p>我们还可以得到，矩阵$A$的主元列是其列空间的基。</p>
<h2 id="四种子空间的维数"><a href="#四种子空间的维数" class="headerlink" title="四种子空间的维数"></a>四种子空间的维数</h2><h3 id="摘要-7"><a href="#摘要-7" class="headerlink" title="摘要"></a>摘要</h3><ol>
<li><p>列空间$\boldsymbol{C}(A)$和行空间$\boldsymbol{C}(A^{\mathrm{T}})$的维数相同，均为$A$的秩$r$。</p>
</li>
<li><p>零空间$\boldsymbol{N}(A)$的维数为$n - r$，$\boldsymbol{N}(A^{\mathrm{T}})$的维数为$m - r$。</p>
</li>
</ol>
<h3 id="引入-2"><a href="#引入-2" class="headerlink" title="引入"></a>引入</h3><p>$m\times n$矩阵$A$的秩直接决定了以下四种子空间的维数：</p>
<ol>
<li><p>行空间$\boldsymbol{C}(A^{\mathrm{T}})$，其为$\boldsymbol{R}^{n}$的子空间 </p>
</li>
<li><p>列空间$\boldsymbol{C}(A)$，其为$\boldsymbol{R}^{m}$的子空间 </p>
</li>
<li><p>零空间$\boldsymbol{N}(A)$，其为$\boldsymbol{R}^{n}$的子空间</p>
</li>
<li><p>剩余零空间$\boldsymbol{N}(A^{\mathrm{T}})$，其为$\boldsymbol{R}^{m}$的子空间</p>
</li>
</ol>
<h3 id="四种子空间的行简化阶梯型矩阵"><a href="#四种子空间的行简化阶梯型矩阵" class="headerlink" title="四种子空间的行简化阶梯型矩阵"></a>四种子空间的行简化阶梯型矩阵</h3><p>对于行空间而言，显然其非零行组成的向量组即为基，而非零行个数即为维数。而对于列空间而言，其主元列组成的向量组为基，主元个数即为维数。由于主元个数与非零行数量显然相等，因此我们可以得到如下的关系：</p>
<blockquote>
<p>定理：</p>
<p>矩阵$A$的行空间与列空间的维数相等，均为矩阵的秩。</p>
</blockquote>
<p>由于我们可以通过依次将某一自由变量设置为1，其余设置为0的方式求解零空间的基向量，因此不难看出，零空间的基向量个数与自由变量数相同。这样，我们可以得出零空间的维数为$n - r$。相似地，当我们求剩余零空间的基时，我们需要将所有非零行的系数设置为0，因此只有零行的系数可以变化。这表明剩余零空间的基中，只有$m - r$个向量，因此其维数为$m - r$</p>
<h3 id="矩阵的四种子空间"><a href="#矩阵的四种子空间" class="headerlink" title="矩阵的四种子空间"></a>矩阵的四种子空间</h3><p>结论：</p>
<ol>
<li><p>$\boldsymbol{C}(A^{\mathrm{T}}) &#x3D; \boldsymbol{C}(R^{\mathrm{T}})$</p>
</li>
<li><p>$\dim\boldsymbol{C}(A)&#x3D; \dim\boldsymbol{C}(R)$，但$\boldsymbol{C}(A) \neq \boldsymbol{C}(R)$</p>
</li>
<li><p>$\boldsymbol{N}(A) &#x3D; \boldsymbol{N}(R)$</p>
</li>
<li><p>$\dim\boldsymbol{N}(A)&#x3D; \dim\boldsymbol{N}(R)$，但$\boldsymbol{N}(A) \neq \boldsymbol{N}(R)$</p>
</li>
</ol>
<h3 id="用秩一矩阵表示矩阵"><a href="#用秩一矩阵表示矩阵" class="headerlink" title="用秩一矩阵表示矩阵"></a>用秩一矩阵表示矩阵</h3><p>秩一矩阵指的是秩为1的矩阵，也就是只有一个非零行的矩阵。例如<br>$$<br>A &#x3D; \begin{bmatrix}<br>2 &amp; 3 &amp; 7 &amp; 8\<br>4 &amp; 6 &amp; 14 &amp; 16 \<br>6 &amp; 9 &amp; 21 &amp; 24 \<br>\end{bmatrix} &#x3D;<br>\begin{bmatrix}<br>1 \ 2 \ 3\<br>\end{bmatrix}<br>\begin{bmatrix}<br>2 &amp; 3 &amp; 7 &amp; 8\<br>\end{bmatrix} &#x3D; \boldsymbol{u}\boldsymbol{v}^{\mathrm{T}}<br>$$<br>不难看出，秩一矩阵可以转化为两个向量的外积。而对于任意的矩阵，在经过LU分解后，可以得到<br>$$<br>A &#x3D; \begin{bmatrix}<br>\boldsymbol{u}<em>{1} &amp; \boldsymbol{u}</em>{2} &amp; \dots &amp; \boldsymbol{u}<em>{m} \<br>\end{bmatrix}<br>\begin{bmatrix}<br>\boldsymbol{v}</em>{1}^{\mathrm{T}} \ \boldsymbol{v}<em>{2}^{\mathrm{T}} \ \vdots \ \boldsymbol{v}</em>{m}^{\mathrm{T}} \<br>\end{bmatrix}<br>$$<br>由此不难看出，任意一个矩阵均可以表示为$m$个秩一矩阵的和。更进一步可以得到，由于并不是所有矩阵都为满秩矩阵，因此实际上任意一个矩阵只需$r$个秩一矩阵即可表示。</p>
<h1 id="正交性"><a href="#正交性" class="headerlink" title="正交性"></a>正交性</h1><h2 id="四个子空间的正交性"><a href="#四个子空间的正交性" class="headerlink" title="四个子空间的正交性"></a>四个子空间的正交性</h2><h3 id="摘要-8"><a href="#摘要-8" class="headerlink" title="摘要"></a>摘要</h3><ol>
<li><p>正交向量满足$\boldsymbol{v}^{\mathrm{T}}\boldsymbol{w} &#x3D; 0$</p>
</li>
<li><p>对于向量空间$\boldsymbol{V}$和$\boldsymbol{W}$，如果$\forall \boldsymbol{v}\in \boldsymbol{V}, \boldsymbol{w} \in \boldsymbol{W}$，$\boldsymbol{v}^{\mathrm{T}}\boldsymbol{w} &#x3D; 0$，那么这两个子空间正交。</p>
</li>
<li><p>矩阵$A$的行空间与零空间正交，其列空间与剩余零空间正交。</p>
</li>
<li><p>$\forall \boldsymbol{x} \in \boldsymbol{R}^{n}$，$\boldsymbol{x} &#x3D; \boldsymbol{x}<em>{\mathrm{row}} + \boldsymbol{x}</em>{\mathrm{null}}$</p>
</li>
<li><p>如果向量空间$\boldsymbol{S}$满足$\dim \boldsymbol{S} &#x3D; d$，那么其每组基都有$d$个向量。同时，如果$d$个向量能够张成$\boldsymbol{S}$，那么这些向量为线性无关；如果这$d$个向量线性无关，那么其可以张成$\boldsymbol{S}$</p>
</li>
</ol>
<h3 id="引入-3"><a href="#引入-3" class="headerlink" title="引入"></a>引入</h3><p>下面说明零空间与行空间之间的关系</p>
<blockquote>
<p>定理：</p>
<p>对于$m\times n$矩阵$A$，$\boldsymbol{N}(A)$和$\boldsymbol{C}(A^{\mathrm{T}})$均为$\boldsymbol{R}^{n}$的子空间，且二者正交</p>
</blockquote>
<blockquote>
<p>证明：</p>
<p>对$\forall\boldsymbol{x}\in \boldsymbol{N}(A)$，其满足$A\boldsymbol{x} &#x3D; 0$。这表明，对于<br>$$<br>A &#x3D; \begin{bmatrix}<br>\boldsymbol{u}<em>{1}^{\mathrm{T}} \ \boldsymbol{u}</em>{2}^{\mathrm{T}} \ \vdots\ \boldsymbol{u}<em>{m}^{\mathrm{T}}\<br>\end{bmatrix}<br>$$<br>中的每一个行向量，都有$\boldsymbol{u}</em>{i}^{\mathrm{T}}\boldsymbol{x} &#x3D; 0$。这表明，对于$\forall\boldsymbol{b}^{\mathrm{T}}\in \boldsymbol{C}(A^{\mathrm{T}})$，$\boldsymbol{b}^{\mathrm{T}}\boldsymbol{x} &#x3D; \sum\limits_{i &#x3D; 1}^{m}c\boldsymbol{u}_{i}^{\mathrm{T}}\boldsymbol{x} &#x3D; 0$。因此$\forall \boldsymbol{v}\in \boldsymbol{V}, \boldsymbol{w} \in \boldsymbol{W}$，$\boldsymbol{v}^{\mathrm{T}}\boldsymbol{w} &#x3D; 0$。这表明这两个子空间正交。</p>
</blockquote>
<p>相似地，有如下定理存在</p>
<blockquote>
<p>对于$m\times n$矩阵$A$，$\boldsymbol{N}(A^{\mathrm{T}})$和$\boldsymbol{C}(A)$均为$\boldsymbol{R}^{m}$的子空间，且二者正交</p>
</blockquote>
<h3 id="正交补"><a href="#正交补" class="headerlink" title="正交补"></a>正交补</h3><blockquote>
<p>定义：</p>
<p>一个子空间$\boldsymbol{V}$的正交补（Orthogonal Complements）指的是包含每个与$\boldsymbol{V}$垂直的向量的子空间。我们将其记为$\boldsymbol{V}^{\perp}$</p>
</blockquote>
<p>在说明下面的一个结论前，我们先说明直和的概念</p>
<blockquote>
<p>定义：</p>
<p>如果$\boldsymbol{V}<em>{1}$和$\boldsymbol{V}</em>{2}$是向量空间$\boldsymbol{V}$的子空间，如果$\forall \boldsymbol{x}\in\boldsymbol{V}$，$\exists! \boldsymbol{x}<em>{1} \in \boldsymbol{V}</em>{1}, \boldsymbol{x}<em>{2} \in \boldsymbol{V}</em>{2}$，那么我们将二者的和空间称为二者的直和（direct sum），记为$\boldsymbol{V}<em>{1} \oplus \boldsymbol{V}</em>{2}$</p>
</blockquote>
<p>可以说明，如果两个子空间正交，那么二者的直和为母空间。</p>
<p>对于$\forall \boldsymbol{x}\in \boldsymbol{R}^{n}$，我们可以通过$A\boldsymbol{x} &#x3D; \boldsymbol{b}$得到列空间的向量$\boldsymbol{b}$。但同时，我们可以将$\boldsymbol{x}$分解为<br>$$<br>\boldsymbol{x} &#x3D; \boldsymbol{x}<em>{\mathrm{row}} + \boldsymbol{x}</em>{\mathrm{null}}<br>$$<br>其中，前者属于行空间，而后者属于零空间。将$A$左乘可以得到<br>$$<br>A \boldsymbol{x} &#x3D; A(\boldsymbol{x}<em>{\mathrm{row}} + \boldsymbol{x}</em>{\mathrm{null}}) &#x3D; A \boldsymbol{x}_{\mathrm{row}} &#x3D; \boldsymbol{b}<br>$$<br>由此不难看出，每一个列空间中的向量均可以从行空间的唯一一个向量得到。</p>
<p>对于两个正交的子空间，只有零向量同时存在于两个子空间。换言之，只有零向量与其自身正交。</p>
<h3 id="组合不同的子空间的基"><a href="#组合不同的子空间的基" class="headerlink" title="组合不同的子空间的基"></a>组合不同的子空间的基</h3><p>我们已经知道，对于向量空间$\boldsymbol{R}^{n}$，只要存在于其中的有$n$个线性无关的向量，那么这些向量必然为其基。由此，对于行空间，我们可以得到$r$个线性无关的向量；而对于零空间，我们可以得到$n - r$个线性无关的向量。同时，这些向量彼此之间也是线性无关的（一个非零向量不能同时存在于两个正交子空间中）。因此，我们得到了$n$个线性无关的向量，这可以作为$\boldsymbol{R}^{n}$的一组基。由此，我们再次说明了，任意一个$\boldsymbol{R}^{n}$中的向量可以表示为行空间于零空间中的向量之和。</p>
<h2 id="投影"><a href="#投影" class="headerlink" title="投影"></a>投影</h2><h3 id="摘要-9"><a href="#摘要-9" class="headerlink" title="摘要"></a>摘要</h3><ol>
<li><p>向量$\boldsymbol{b}$在向量$\boldsymbol{a}$所在直线的投影为$\boldsymbol{p} &#x3D; \boldsymbol{a} \cdot \dfrac{\boldsymbol{a}^{\mathrm{T}}\boldsymbol{b}}{\boldsymbol{a}^{\mathrm{T}}\boldsymbol{a}}$</p>
</li>
<li><p>差向量$\boldsymbol{e} &#x3D; \boldsymbol{b} - \boldsymbol{p}$与$\boldsymbol{a}$垂直</p>
</li>
<li><p>向量$\boldsymbol{b}$在子空间$\boldsymbol{S}$上的投影为$\boldsymbol{S}$中最近的向量$\boldsymbol{p}$，$\boldsymbol{b} - \boldsymbol{p}$与$\boldsymbol{S}$垂直</p>
</li>
<li><p>$A^{\mathrm{T}} A$只有在$A$的列向量线性无关时可逆。$\boldsymbol{N}(A^{\mathrm{T}} A) &#x3D; \boldsymbol{N}(A)$</p>
</li>
<li><p>向量$\boldsymbol{b}$在矩阵$A$的列空间上的投影为$\boldsymbol{p} &#x3D; A(A^{\mathrm{T}} A)^{-1}A^{\mathrm{T}} \boldsymbol{b}$</p>
</li>
<li><p>$\boldsymbol{C}(A)$的投影矩阵为$P &#x3D; A(A^{\mathrm{T}} A)^{-1}A^{\mathrm{T}}$，其满足$\boldsymbol{p} &#x3D; P\boldsymbol{b}$，以及$P &#x3D; P^{2} &#x3D; P^{\mathrm{T}}$</p>
</li>
</ol>
<h3 id="投影到线上"><a href="#投影到线上" class="headerlink" title="投影到线上"></a>投影到线上</h3><p>假设将向量$\boldsymbol{b}$投影到向量$\boldsymbol{a}$所在直线上，那么显然$\boldsymbol{b}$的投影$\boldsymbol{p} &#x3D; \hat{x}\boldsymbol{a}$，其中$\hat{x}$为一个数。同时，$\boldsymbol{e} &#x3D; \boldsymbol{b} - \boldsymbol{p}$与$\boldsymbol{a}$垂直，因此我们可以得到<br>$$<br>\boldsymbol{a}^{\mathrm{T}}(\boldsymbol{b} - \hat{x}\boldsymbol{a}) &#x3D; 0<br>$$<br>由此不难解得<br>$$<br>\hat{x} &#x3D; \dfrac{\boldsymbol{a}^{\mathrm{T}}\boldsymbol{b}}{\boldsymbol{a}^{\mathrm{T}}\boldsymbol{a}}<br>$$<br>如果假设投影矩阵为$P$，那么其满足$\boldsymbol{p} &#x3D; P\boldsymbol{b}$。由于$\boldsymbol{p} &#x3D; \boldsymbol{a} \dfrac{\boldsymbol{a}^{\mathrm{T}}\boldsymbol{b}}{\boldsymbol{a}^{\mathrm{T}}\boldsymbol{a}}$，因此可以得到<br>$$<br>P &#x3D; \dfrac{\boldsymbol{a}\boldsymbol{a}^{\mathrm{T}}}{\boldsymbol{a}^{\mathrm{T}}\boldsymbol{a}}<br>$$<br>不难看出，$P$本质上是由矩阵$\boldsymbol{a}\boldsymbol{a}^{\mathrm{T}}$除以数$\boldsymbol{a}^{\mathrm{T}}\boldsymbol{a}$得到的。因此$P$为秩一矩阵。</p>
<h3 id="投影到面上"><a href="#投影到面上" class="headerlink" title="投影到面上"></a>投影到面上</h3><p>假设在$\boldsymbol{R}^{m}$中有$n$个线性无关的向量$\boldsymbol{a}<em>{1}, \dots, \boldsymbol{a}</em>{n}$，那么对于$\forall\boldsymbol{b} \in \boldsymbol{R}^{m}$，我们需要寻找其在$\mathrm{Span}(\boldsymbol{a}<em>{1}, \dots, \boldsymbol{a}</em>{n})$上的投影$\boldsymbol{p} &#x3D; \sum\limits_{i &#x3D; 1}^{n} \hat{x}<em>{i}\boldsymbol{a}</em>{i}$。由于$\mathrm{Span}(\boldsymbol{a}<em>{1}, \dots, \boldsymbol{a}</em>{n}) &#x3D; \boldsymbol{C}(A)$，其中$A$为以$\boldsymbol{a}<em>{1}, \dots, \boldsymbol{a}</em>{n}$作为列向量的矩阵，因此$\boldsymbol{p} &#x3D; A\hat{\boldsymbol{x}}$，其中$\hat{\boldsymbol{x}} &#x3D; [\hat{x}<em>{1}\ \hat{x}</em>{2}\ \dots\ \hat{x}_{n}]^{\mathrm{T}}$</p>
<p>差向量$\boldsymbol{e} &#x3D; \boldsymbol{b} - A\hat{\boldsymbol{x}}$与$A$中每个列向量均垂直，因此可以得到<br>$$<br>A^{\mathrm{T}}(\boldsymbol{b} - A\hat{\boldsymbol{x}}) &#x3D; 0<br>$$<br>由此可得<br>$$<br>A^{\mathrm{T}} A\hat{\boldsymbol{x}} &#x3D; A^{\mathrm{T}}\boldsymbol{b}<br>$$<br>我们将这个方程称为“正规方程”，并由此可得<br>$$<br>\hat{\boldsymbol{x}} &#x3D; (A^{\mathrm{T}} A)^{-1}A^{\mathrm{T}}\boldsymbol{b} P &#x3D; A(A^{\mathrm{T}} A)^{-1}A^{\mathrm{T}}<br>$$</p>
<p>对于矩阵$A^{\mathrm{T}} A$，有一个很重要的定理 </p>
<blockquote>
<p>定理：</p>
<p>对于矩阵$A$，$\boldsymbol{N}(A^{\mathrm{T}} A) &#x3D; \boldsymbol{N}(A)$</p>
</blockquote>
<blockquote>
<p>证明：</p>
<ol>
<li><p>证明$\boldsymbol{N}(A)$中向量均在$\boldsymbol{N}(A^{\mathrm{T}} A)$中：假如$\boldsymbol{x}\in \boldsymbol{N}(A)$，那么$A\boldsymbol{x} &#x3D; 0$。将其左乘$A^{\mathrm{T}}$不难得到$A^{\mathrm{T}} A \boldsymbol{x} &#x3D; 0$，这样$\boldsymbol{x} \in \boldsymbol{N}(A^{\mathrm{T}} A)$</p>
</li>
<li><p>证明$\boldsymbol{N}(A^{\mathrm{T}} A)$中的向量均在$\boldsymbol{N}(A)$中：假如$\boldsymbol{x} \in \boldsymbol{N}(A^{\mathrm{T}} A)$，那么$A^{\mathrm{T}} A\boldsymbol{x} &#x3D; 0$。将其左乘$\boldsymbol{x}^{\mathrm{T}}$可以得到<br>$$<br>\boldsymbol{x}^{\mathrm{T}} A^{\mathrm{T}} A\boldsymbol{x} &#x3D; (A\boldsymbol{x})^{\mathrm{T}} A\boldsymbol{x} &#x3D; ||A\boldsymbol{x}||^{2} &#x3D; 0<br>$$<br>这表明，$A\boldsymbol{x}$的长度为0，因此其为零向量，即$A\boldsymbol{x} &#x3D; 0$.</p>
</li>
</ol>
</blockquote>
<p>由上述定理不难得出，只有当$A$的列线性无关时，$\boldsymbol{N}(A^{\mathrm{T}} A) &#x3D; \boldsymbol{Z}$，即$A^{\mathrm{T}} A$可逆。由此不难得到以下推论</p>
<blockquote>
<p>推论：</p>
<p>对于矩阵$A$，$A^{\mathrm{T}} A$可逆的充要条件是$A$的列线性无关</p>
</blockquote>
<h2 id="最小二乘近似"><a href="#最小二乘近似" class="headerlink" title="最小二乘近似"></a>最小二乘近似</h2><h3 id="摘要-10"><a href="#摘要-10" class="headerlink" title="摘要"></a>摘要</h3><ol>
<li><p>通过求解$A^{\mathrm{T}} A\hat{\boldsymbol{x}} &#x3D; A^{\mathrm{T}}\boldsymbol{b}$可以得到$\boldsymbol{b}$在$\boldsymbol{C}(A)$上的投影$\boldsymbol{p} &#x3D; A\hat{\boldsymbol{x}}$</p>
</li>
<li><p>当$A\boldsymbol{x} &#x3D; \boldsymbol{b}$无解时，$\hat{\boldsymbol{x}}$为最小二乘解，其满足$||\boldsymbol{b} - A\hat{\boldsymbol{x}}||^{2}$最小。为了使$E &#x3D; ||\boldsymbol{b} - A\hat{\boldsymbol{x}}||^{2}$最小，求$\dfrac{\partial E}{\partial x_{i}} &#x3D; 0$。这样也可以得到$A^{\mathrm{T}} A\hat{\boldsymbol{x}} &#x3D; A^{\mathrm{T}}\boldsymbol{b}$</p>
</li>
<li><p>为了线性拟合$(t_{1}, b_{1}), \dots, (t_{m}, b_{m})$，矩阵$A &#x3D; \begin{bmatrix}<br>1 &amp; t_{1}\<br>1 &amp; t_{2}\<br>\vdots &amp; \vdots \<br>1 &amp; t_{m}\<br>\end{bmatrix}$，这样$A^{\mathrm{T}} A &#x3D; \begin{bmatrix}<br>m &amp; \sum\limits_{i &#x3D; 1}^{m}t_{i} \<br>\sum\limits_{i &#x3D; 1}^{m}t_{i} &amp; \sum\limits_{i &#x3D; 1}^{m}t_{i}^{2} \<br>\end{bmatrix}$，而$A^{\mathrm{T}} \boldsymbol{b} &#x3D; \begin{bmatrix}<br>\sum\limits_{i &#x3D; 1}^{m}b_{i} \<br>\sum\limits_{i &#x3D; 1}^{m}t_{i}b_{i} \<br>\end{bmatrix}$</p>
</li>
</ol>
<h3 id="最小化差向量"><a href="#最小化差向量" class="headerlink" title="最小化差向量"></a>最小化差向量</h3><p>对于任意的方程$A\boldsymbol{x} &#x3D; \boldsymbol{b}$，其并不一定有解。我们可以将其分解为$\boldsymbol{b} &#x3D; \boldsymbol{p} + \boldsymbol{e}$，其中$\boldsymbol{p}\in \boldsymbol{C}(A)$，同时$\boldsymbol{e}$与$\boldsymbol{p}$垂直。这样，由于$A\boldsymbol{x} - \boldsymbol{b}$与$A\boldsymbol{x} - \boldsymbol{p}$垂直，我们可以得到以下方程<br>$$<br>||A\boldsymbol{x} - \boldsymbol{b}||^{2} &#x3D; ||A\boldsymbol{x} - \boldsymbol{p}||^{2} + ||\boldsymbol{e}||^{2}<br>$$<br>将$\hat{\boldsymbol{x}}$代入不难发现，由于$||A\hat{\boldsymbol{x}} - \boldsymbol{p}||^{2} &#x3D; 0$，因此此时$E &#x3D; ||A\boldsymbol{x} - \boldsymbol{b}||^{2}$最小。</p>
<h3 id="最小二乘的大图景"><a href="#最小二乘的大图景" class="headerlink" title="最小二乘的大图景"></a>最小二乘的大图景</h3><p>我们已经论证过，$\forall\boldsymbol{x}\in \boldsymbol{R}^{n}$，$\exists!\boldsymbol{x}<em>{\mathrm{row}} \in \boldsymbol{C}(A^{\mathrm{T}}), \boldsymbol{x}</em>{\mathrm{null}} \in \boldsymbol{N}(A)$，$\boldsymbol{x} &#x3D; \boldsymbol{x}<em>{\mathrm{row}} + \boldsymbol{x}</em>{\mathrm{null}}$。因此我们可以类似地得到，$\forall \boldsymbol{b} \in \boldsymbol{R}^{m}$，$\exists!\boldsymbol{p} \in \boldsymbol{C}(A)$，$\boldsymbol{e} \in \boldsymbol{N}(A^{\mathrm{T}})$，$\boldsymbol{b} &#x3D; \boldsymbol{p} + \boldsymbol{e}$。</p>
<p>由于$A$的列向量线性无关（为什么？），因此其零空间现在仅为一个点。这确保了$A^{\mathrm{T}} A$可逆，从而使我们能够解出$\hat{\boldsymbol{x}}$</p>
<h3 id="拟合直线"><a href="#拟合直线" class="headerlink" title="拟合直线"></a>拟合直线</h3><p>假设在二维空间中拟合直线。这其实是试图寻找<br>$$<br>A\boldsymbol{x} &#x3D; \begin{bmatrix}<br>1 &amp; t_{1}\<br>1 &amp; t_{2}\<br>\vdots &amp; \vdots \<br>1 &amp; t_{m}\<br>\end{bmatrix}\begin{bmatrix}<br>C \ D \<br>\end{bmatrix} &#x3D; \begin{bmatrix}<br>b_{1} \ b_{2} \ \vdots \ b_{m}\<br>\end{bmatrix} &#x3D; \boldsymbol{b}<br>$$<br>的解。然而这通常无法实现。此时，我们的任务就变成了寻找$\boldsymbol{x}$，使得$E &#x3D; ||A \boldsymbol{x} - \boldsymbol{b}||^{2}$最小。要求最小值，我们对$E$求偏导，并使其等于0<br>$$<br>\left{ %在equation环境下使用，用\left{命令添加左大括号，用\right.以打点.结束<br>    \begin{aligned}<br>\dfrac{\partial E}{\partial C} &amp; &#x3D; \sum\limits_{i &#x3D; 1}^{m}2(C + Dt_{i} - b_{i}) &#x3D; 0 \<br>\dfrac{\partial E}{\partial D} &amp; &#x3D; \sum\limits_{i &#x3D; 1}^{m}2t_{i}(C + Dt_{i} - b_{i}) &#x3D; 0  \<br>    \end{aligned}<br>\right.<br>$$<br>由此不难得到如下矩阵方程<br>$$<br>\begin{bmatrix}<br>m &amp; \sum\limits_{i &#x3D; 1}^{m}t_{i} \<br>\sum\limits_{i &#x3D; 1}^{m}t_{i} &amp; \sum\limits_{i &#x3D; 1}^{m}t_{i}^{2} \<br>\end{bmatrix}<br>\begin{bmatrix}<br>C \<br>D \<br>\end{bmatrix} &#x3D;<br>\begin{bmatrix}<br>\sum\limits_{i &#x3D; 1}^{m}b_{i} \<br>\sum\limits_{i &#x3D; 1}^{m}t_{i}b_{i} \<br>\end{bmatrix}<br>$$这就是我们之前得到的正规方程（normal equation）<br>$$<br>A^{\mathrm{T}} A\hat{\boldsymbol{x}} &#x3D; A^{\mathrm{T}} \boldsymbol{b}<br>$$</p>
<h3 id="列向量线性相关的情况"><a href="#列向量线性相关的情况" class="headerlink" title="列向量线性相关的情况"></a>列向量线性相关的情况</h3><p>见伪逆相关部分。矩阵$A$的伪逆会选择$A\hat{\boldsymbol{x}} &#x3D; \boldsymbol{p}$的最短解。</p>
<h2 id="正交基与Gram-Schmidt正交化"><a href="#正交基与Gram-Schmidt正交化" class="headerlink" title="正交基与Gram-Schmidt正交化"></a>正交基与Gram-Schmidt正交化</h2><h3 id="摘要-11"><a href="#摘要-11" class="headerlink" title="摘要"></a>摘要</h3><ol>
<li><p>如果$\boldsymbol{q}<em>{i}^{\mathrm{T}}\boldsymbol{q} &#x3D; \delta</em>{ij}$，那么这些向量正交，并且由其作为列向量的矩阵$Q$满足$Q^{\mathrm{T}} Q &#x3D; I$</p>
</li>
<li><p>如果上述的$Q$为方阵，那么$Q^{\mathrm{T}} &#x3D; Q^{-1}$，并且$QQ^{\mathrm{T}} &#x3D; I$。我们将$Q$称为正交矩阵。</p>
</li>
<li><p>$Q\boldsymbol{x} &#x3D; \boldsymbol{b}$的最小二乘解为$\hat{\boldsymbol{x}} &#x3D; Q^{\mathrm{T}}\boldsymbol{b}$。$\boldsymbol{b}$的投影为$\boldsymbol{p} &#x3D; QQ^{\mathrm{T}}\boldsymbol{b}$</p>
</li>
<li><p>Gram-Schmidt正交化将线性无关向量$\boldsymbol{a}<em>{i}$变为正交向量$\boldsymbol{q}</em>{i}$，其按照如下方式进行：</p>
</li>
</ol>
<p> 4.1 $\boldsymbol{q}<em>{1} &#x3D; \dfrac{\boldsymbol{a}</em>{1}}{||\boldsymbol{a}_{1}||}$</p>
<p> 4.2 $\boldsymbol{q}<em>{i} &#x3D; \dfrac{\boldsymbol{a}</em>{i} - \boldsymbol{p}<em>{i}}{||\boldsymbol{a}</em>{i} - \boldsymbol{p}<em>{i}||}$，其中投影$\boldsymbol{p}</em>{i} &#x3D; \sum\limits_{j &#x3D; 1}^{i - 1} (\boldsymbol{a}^{\mathrm{T}}\boldsymbol{q}<em>{j})\boldsymbol{q}</em>{j}$</p>
<ol start="5">
<li>每个$\boldsymbol{a}<em>{i}$都是$\boldsymbol{q}</em>{1}$到$\boldsymbol{q}<em>{i}$的线性组合，因此我们可以将由$\boldsymbol{a}</em>{i}$组成的列线性无关矩阵$A$分解为正交矩阵$Q$与上三角型矩阵$R$之积（$A &#x3D; QR$）。</li>
</ol>
<h3 id="引入-4"><a href="#引入-4" class="headerlink" title="引入"></a>引入</h3><p>每个排列矩阵（permutation matrix）都是正交矩阵。<br>正交矩阵满足以下性质：</p>
<blockquote>
<p>定理:</p>
<p>如果矩阵$Q$为正交矩阵，那么其满足：</p>
<ol>
<li><p>$||Q\boldsymbol{x}|| &#x3D; ||\boldsymbol{x}||$</p>
</li>
<li><p>$\boldsymbol{x}\cdot\boldsymbol{y} &#x3D; (Q\boldsymbol{x}) \cdot (Q\boldsymbol{y})$</p>
</li>
</ol>
</blockquote>
<blockquote>
<p>证明：</p>
<ol>
<li><p>$||Q\boldsymbol{x}||^{2} &#x3D; (Q\boldsymbol{x})^{\mathrm{T}}(Q\boldsymbol{x}) &#x3D; \boldsymbol{x}^{\mathrm{T}} Q^{\mathrm{T}} Q \boldsymbol{x} &#x3D; \boldsymbol{x}^{\mathrm{T}}\boldsymbol{x}$</p>
</li>
<li><p>$(Q\boldsymbol{x})^{\mathrm{T}}(Q\boldsymbol{y}) &#x3D; \boldsymbol{x}^{\mathrm{T}}\boldsymbol{Q}^{\mathrm{T}} Q\boldsymbol{y} &#x3D; \boldsymbol{x}^{\mathrm{T}}\boldsymbol{y}$</p>
</li>
</ol>
</blockquote>
<h3 id="使用正交基的投影：用-Q-代替-A"><a href="#使用正交基的投影：用-Q-代替-A" class="headerlink" title="使用正交基的投影：用$Q$代替$A$"></a>使用正交基的投影：用$Q$代替$A$</h3><p>对于一般的矩阵$A$，向量$\boldsymbol{b}$在$\boldsymbol{C}(A)$上的投影为$\boldsymbol{p} &#x3D; A\hat{\boldsymbol{x}}$。此时正规方程为<br>$$<br>A^{\mathrm{T}} A \hat{\boldsymbol{x}} &#x3D; A^{\mathrm{T}}\boldsymbol{b}<br>$$<br>并且<br>$$<br>\hat{\boldsymbol{x}} &#x3D; (A^{\mathrm{T}} A)^{-1}A^{\mathrm{T}}\boldsymbol{b} P &#x3D; A(A^{\mathrm{T}} A)^{-1}A^{\mathrm{T}}<br>$$<br>以及<br>$$<br>\boldsymbol{p} &#x3D; A(A^{\mathrm{T}} A)^{-1}A^{\mathrm{T}}\boldsymbol{b}<br>$$</p>
<p>将$A$替换为$Q$可以得到<br>$$<br>\hat{\boldsymbol{x}} &#x3D; A^{\mathrm{T}}\boldsymbol{b}  P &#x3D; QQ^{\mathrm{T}}<br>$$<br>以及<br>$$<br>\boldsymbol{p} &#x3D; QQ^{\mathrm{T}}\boldsymbol{b} &#x3D; \sum\limits_{i &#x3D; 1}^{n} \boldsymbol{q}<em>{i}(\boldsymbol{q}</em>{i}^{\mathrm{T}}\boldsymbol{b})<br>$$</p>
<h3 id="Gram-Schmidt正交化"><a href="#Gram-Schmidt正交化" class="headerlink" title="Gram-Schmidt正交化"></a>Gram-Schmidt正交化</h3><p>其过程如下：</p>
<ol>
<li><p>任选一个向量$\boldsymbol{a}<em>{1}$归一化：<br>$$<br>\boldsymbol{b}</em>{1} &#x3D; \boldsymbol{a}_{1}<br>$$</p>
</li>
<li><p>第二个正交向量$\boldsymbol{b}<em>{2}$应当与$\boldsymbol{b}</em>{1}$垂直，因此我们选择$\boldsymbol{a}<em>{2}$与其在$\boldsymbol{b}</em>{1}$上投影之差：<br>$$<br>\boldsymbol{b}<em>{2} &#x3D; \boldsymbol{a}</em>{2} - \dfrac{\boldsymbol{b}<em>{1}^{\mathrm{T}}\boldsymbol{a}</em>{2}}{\boldsymbol{b}<em>{1}^{\mathrm{T}}\boldsymbol{b}</em>{1}}\boldsymbol{b}_{1}<br>$$</p>
</li>
<li><p>第三个正交向量$\boldsymbol{b}<em>{3}$应当与$\boldsymbol{b}</em>{1}$和$\boldsymbol{b}<em>{2}$垂直，因此我们选择$\boldsymbol{a}</em>{3}$与其在$\boldsymbol{b}<em>{1}$和$\boldsymbol{b}</em>{2}$上的投影之差：<br>$$<br>\boldsymbol{b}<em>{3} &#x3D; \boldsymbol{a}</em>{3} - \dfrac{\boldsymbol{b}<em>{1}^{\mathrm{T}}\boldsymbol{a}</em>{3}}{\boldsymbol{b}<em>{1}^{\mathrm{T}}\boldsymbol{b}</em>{1}}\boldsymbol{b}<em>{1} - \dfrac{\boldsymbol{b}</em>{2}^{\mathrm{T}}\boldsymbol{a}<em>{3}}{\boldsymbol{b}</em>{2}^{\mathrm{T}}\boldsymbol{b}<em>{2}}\boldsymbol{b}</em>{2}<br>$$</p>
</li>
<li><p>重复上述步骤，直到所有向量都正交化。</p>
</li>
</ol>
<h3 id="QR分解"><a href="#QR分解" class="headerlink" title="QR分解"></a>QR分解</h3><p>以只有三个向量的例子为例。假设$A &#x3D; \begin{bmatrix}<br>\boldsymbol{a} &amp; \boldsymbol{b} &amp; \boldsymbol{c} \<br>\end{bmatrix}$，其QR分解过程如下：</p>
<ol>
<li><p>将每个正交向量的表达式按照如下方式重写：<br>$$<br>\left{<br>\begin{aligned}<br>\boldsymbol{b}<em>{1} &#x3D; &amp; \boldsymbol{a}</em>{1} \<br>\boldsymbol{b}<em>{2} &#x3D; &amp; \boldsymbol{a}</em>{2} - \dfrac{\boldsymbol{b}<em>{1}\cdot\boldsymbol{a}</em>{2}}{\boldsymbol{b}<em>{1}\cdot\boldsymbol{b}</em>{1}}\boldsymbol{b}<em>{1} \<br>\boldsymbol{b}</em>{3} &#x3D; &amp; \boldsymbol{a}<em>{3} - \dfrac{\boldsymbol{b}</em>{1}\cdot\boldsymbol{a}<em>{3}}{\boldsymbol{b}</em>{1}\cdot\boldsymbol{b}<em>{1}}\boldsymbol{b}</em>{1} - \dfrac{\boldsymbol{b}<em>{2}\cdot\boldsymbol{a}</em>{3}}{\boldsymbol{b}<em>{2}\cdot\boldsymbol{b}</em>{2}}\boldsymbol{b}_{2}<br>\end{aligned}<br>\right.<br>$$</p>
</li>
<li><p>上式可变形为<br>$$<br>\left{ %在equation环境下使用，用\left{命令添加左大括号，用\right.以打点.结束<br>\begin{aligned}<br>\boldsymbol{q}<em>{1}||\boldsymbol{b}</em>{1}|| &#x3D; &amp; \boldsymbol{a}<em>{1} \<br>\boldsymbol{q}</em>{2}||\boldsymbol{b}<em>{2}|| &#x3D; &amp; \boldsymbol{a}</em>{2} - (\boldsymbol{q}<em>{1}\cdot\boldsymbol{a}</em>{2})\boldsymbol{q}<em>{1} \<br>\boldsymbol{q}</em>{3}||\boldsymbol{b}<em>{3}|| &#x3D; &amp; \boldsymbol{a}</em>{3} - (\boldsymbol{q}<em>{1}\cdot\boldsymbol{a}</em>{3})\boldsymbol{q}<em>{1} - (\boldsymbol{q}</em>{2}\cdot\boldsymbol{a}<em>{3})\boldsymbol{q}</em>{2} \<br>\end{aligned}<br>\right.<br>$$<br>其中，$\boldsymbol{q}<em>{i}$为$\boldsymbol{b}</em>{i}$归一化得到的单位向量。</p>
</li>
<li><p>注意到$||\boldsymbol{b}<em>{i}|| &#x3D; \boldsymbol{q}</em>{i}\cdot\boldsymbol{a}<em>{i}$（然而注意力涣散了一个小时才注意到），由此可得<br>$$<br>\left{ %在equation环境下使用，用\left{命令添加左大括号，用\right.以打点.结束<br>\begin{aligned}<br>\boldsymbol{q}</em>{1}(\boldsymbol{q}<em>{1}\cdot\boldsymbol{a}</em>{1}) &#x3D; &amp; \boldsymbol{a}<em>{1} \<br>\boldsymbol{q}</em>{2}(\boldsymbol{q}<em>{2}\cdot\boldsymbol{a}</em>{2}) &#x3D; &amp; \boldsymbol{a}<em>{2} - (\boldsymbol{q}</em>{1}\cdot\boldsymbol{a}<em>{2})\boldsymbol{q}</em>{1} \<br>\boldsymbol{q}<em>{3}(\boldsymbol{q}</em>{3}\cdot\boldsymbol{a}<em>{3}) &#x3D; &amp; \boldsymbol{a}</em>{3} - (\boldsymbol{q}<em>{1}\cdot\boldsymbol{a}</em>{3})\boldsymbol{q}<em>{1} - (\boldsymbol{q}</em>{2}\cdot\boldsymbol{a}<em>{3})\boldsymbol{q}</em>{2} \<br>\end{aligned}<br>\right.<br>$$<br>写成矩阵形式即可得到<br>$$<br>\begin{bmatrix}<br>\boldsymbol{a} &amp; \boldsymbol{b} &amp; \boldsymbol{c} \<br>\end{bmatrix} &#x3D;<br>\begin{bmatrix}<br>\boldsymbol{q}<em>{1} &amp; \boldsymbol{q}</em>{2} &amp; \boldsymbol{q}<em>{3} \<br>\end{bmatrix}<br>\begin{bmatrix}<br>\boldsymbol{q}</em>{1}^{\mathrm{T}}\boldsymbol{a}<em>{1} &amp; \boldsymbol{q}</em>{1}^{\mathrm{T}}\boldsymbol{a}<em>{2} &amp; \boldsymbol{q}</em>{1}^{\mathrm{T}}\boldsymbol{a}<em>{3} \<br>0 &amp; \boldsymbol{q}</em>{2}^{\mathrm{T}}\boldsymbol{a}<em>{2} &amp; \boldsymbol{q}</em>{2}^{\mathrm{T}}\boldsymbol{a}<em>{3} \<br>0 &amp; 0 &amp; \boldsymbol{q}</em>{3}^{\mathrm{T}}\boldsymbol{a}_{3} \<br>\end{bmatrix}<br>$$</p>
</li>
</ol>
<h1 id="行列式"><a href="#行列式" class="headerlink" title="行列式"></a>行列式</h1><h2 id="行列式性质"><a href="#行列式性质" class="headerlink" title="行列式性质"></a>行列式性质</h2><h3 id="摘要-12"><a href="#摘要-12" class="headerlink" title="摘要"></a>摘要</h3><ol>
<li><p>当矩阵$A$的列线性相关时，我们称这样的矩阵为奇异矩阵（Singular Matrix）。奇异矩阵满足$\det A &#x3D; 0$</p>
</li>
<li><p>行交换使得行列式变号 </p>
</li>
<li><p>$\det BA &#x3D; \det B \det A$，$\det A^{\mathrm{T}} &#x3D; \det A$</p>
</li>
<li><p>$\begin{vmatrix}<br> ta &amp; b \<br> tc &amp; d \</p>
</li>
</ol>
<p>\end{vmatrix} &#x3D;<br>t\begin{vmatrix}<br>        a &amp; b \<br>        c &amp; d \<br>\end{vmatrix}$，$\begin{vmatrix}<br>        a + a’ &amp; b + b’ \<br>        c &amp; d \<br>    \end{vmatrix} &#x3D;<br>    \begin{vmatrix}<br>        a &amp; b \<br>        c &amp; d \<br>    \end{vmatrix} + \begin{vmatrix}<br>        a’ &amp; b’ \<br>        c &amp; d \<br>\end{vmatrix}$</p>
<ol start="5">
<li>$\begin{vmatrix}<br> a &amp; b \<br> c - la &amp; d - lb \<br> \end{vmatrix} &#x3D; \begin{vmatrix}<br> a &amp; b \<br> c &amp; d \</li>
</ol>
<p>\end{vmatrix}$</p>
<h2 id="排列和余子式"><a href="#排列和余子式" class="headerlink" title="排列和余子式"></a>排列和余子式</h2><h3 id="摘要-13"><a href="#摘要-13" class="headerlink" title="摘要"></a>摘要</h3><ol>
<li>矩阵$A$的行列式可以按照第$i$行展开为$\det A &#x3D; \sum\limits_{j &#x3D; 1}^{n}(-1)^{i + j}a_{ij}M_{ij}$，其中$M_{ij}$被称为余子式（cofactor）。也可以按照将符号与余子式相乘，得到代数余子式$C_{ij} &#x3D; (-1)^{ij}M_{ij}$，这样行列式可以展开为$\det A &#x3D; \sum\limits_{i &#x3D; 1}^{n}a_{ij}C_{ij}$</li>
</ol>
<h2 id="Cramer法则"><a href="#Cramer法则" class="headerlink" title="Cramer法则"></a>Cramer法则</h2><h3 id="摘要-14"><a href="#摘要-14" class="headerlink" title="摘要"></a>摘要</h3><ol>
<li><p>$A^{-1} &#x3D; \dfrac{C^{\mathrm{T}}}{\det A}$，其中$C^{\mathrm{T}}$为矩阵$A$的伴随矩阵（Adjoint Matrix），其满足$(C^{\mathrm{T}})<em>{ij} &#x3D; C</em>{ji}$</p>
</li>
<li><p>Cramer法则指的是在方程$A\boldsymbol{x} &#x3D; \boldsymbol{b}$中，$x_{i} &#x3D; \dfrac{\det B_{i}}{\det A}$，其中$\det B_{i}$是将$A$的第$i$列换为$\boldsymbol{b}$得到的行列式。</p>
</li>
</ol>
<h1 id="特征值和特征向量"><a href="#特征值和特征向量" class="headerlink" title="特征值和特征向量"></a>特征值和特征向量</h1><h2 id="特征值简介"><a href="#特征值简介" class="headerlink" title="特征值简介"></a>特征值简介</h2><h3 id="摘要-15"><a href="#摘要-15" class="headerlink" title="摘要"></a>摘要</h3><ol>
<li><p>对于形如$A\boldsymbol{x} &#x3D; \lambda\boldsymbol{x}$的方程，我们将$\boldsymbol{x}$称为特征向量，$\lambda$称为特征值</p>
</li>
<li><p>$A^{n}\boldsymbol{x} &#x3D; \lambda^{n}\boldsymbol{x}$，$A^{-1}\boldsymbol{x} &#x3D; \lambda^{-1}\boldsymbol{x}$，$(A + cI)\boldsymbol{x} &#x3D; (\lambda + c)\boldsymbol{x}$</p>
</li>
<li><p>如果$A\boldsymbol{x} &#x3D; \lambda\boldsymbol{x}$，那么$(A - \lambda I)\boldsymbol{x} &#x3D; 0$，同时$\det (A - \lambda I) &#x3D; 0$</p>
</li>
</ol>
<h3 id="特征值方程"><a href="#特征值方程" class="headerlink" title="特征值方程"></a>特征值方程</h3><p>如果$(A - \lambda I)\boldsymbol{x} &#x3D; 0$有非零解，那么存在$A$的特征向量。而由于只有当$\det (A - \lambda I) &#x3D; 0$时其才存在非零解，因此通过$\det (A - \lambda I) &#x3D; 0$可以解出特征值$\lambda$。</p>
<h3 id="迹和行列式"><a href="#迹和行列式" class="headerlink" title="迹和行列式"></a>迹和行列式</h3><p>$n$个特征值之积等于行列式的值，$n$个特征值之和等于对角线元素之和。我们将对角线元素之和称为矩阵的迹。</p>
<h3 id="公共特征向量"><a href="#公共特征向量" class="headerlink" title="公共特征向量"></a>公共特征向量</h3><p>只有当矩阵$A$和$B$满足$AB &#x3D; BA$时，其才共享$n$个特征向量。</p>
<h2 id="矩阵对角化"><a href="#矩阵对角化" class="headerlink" title="矩阵对角化"></a>矩阵对角化</h2><h3 id="摘要-16"><a href="#摘要-16" class="headerlink" title="摘要"></a>摘要</h3><ol>
<li><p>假设$X$中每一列为特征向量$\boldsymbol{x}<em>{i}$，$\Lambda$中对应列为$\lambda</em>{i}\boldsymbol{e}_{i}$，那么我们可以将矩阵$A$的所有特征方程合写为$AX &#x3D; X\Lambda$。$\Lambda$为对角矩阵。同理有$A^{n}X &#x3D; X\Lambda^{n}$</p>
</li>
<li><p>$n$个线性无关特征向量组成的矩阵$X$可以将$A$对角化为$\Lambda$，即$\Lambda &#x3D; X^{-1}AX$。也可用$\Lambda$表示$A$，即$A &#x3D; X\Lambda X^{-1}$。同理$\Lambda^{n} &#x3D; X^{-1}A^{n}X$，$A^{n} &#x3D; X\Lambda^{n}X^{-1}$</p>
</li>
<li><p>对于多个特征向量，如果其特征值各不相同，那么$X$为可逆矩阵，$A$可以对角化。反之，如果存在特征向量的特征值相同的情况，那么$A$可能存在线性相关的特征向量（也可能所有特征向量线性无关），此时$X$不可逆。</p>
</li>
<li><p>对于每个可以表示为$C &#x3D; B^{-1}AB$的矩阵$C$，其特征值与$A$相同。我们称$C$与$A$相似（$C$ is similar to $A$）。</p>
</li>
</ol>
<h3 id="引入-5"><a href="#引入-5" class="headerlink" title="引入"></a>引入</h3><p>关于对角化需要注意以下两点：</p>
<ol>
<li><p>假设$A$的特征值$\lambda_{i}$各不相同，那么其特征向量$\boldsymbol{x}_{i}$也线性无关，此时$X$为可逆矩阵。任何特征值不重复的矩阵可以被对角化。</p>
</li>
<li><p>可对角化与可逆并不相同。可对角化与线性无关的特征向量是否足够有关。</p>
</li>
</ol>
<h3 id="相似矩阵：相同特征值"><a href="#相似矩阵：相同特征值" class="headerlink" title="相似矩阵：相同特征值"></a>相似矩阵：相同特征值</h3><p>假设特征值矩阵$\Lambda$固定，通过改变特征向量矩阵$X$，我们可以得到不同的矩阵$A &#x3D; X\Lambda X^{-1}$。由这种思路，如果矩阵$A$可以表示为$A &#x3D; BCB^{-1}$，那么我们称$A$与$C$相似。注意这里之所以用$C$代替$\Lambda$，是因为$C$不一定是对角矩阵。而用$B$代替$X$是因为$B$的列不一定是特征向量，同时只要$B$满足可逆即可。对于相似的矩阵有下面的命题成立：</p>
<blockquote>
<p>定理：</p>
<p>两个相似的矩阵的特征值相同。</p>
</blockquote>
<blockquote>
<p>证明：</p>
<p>假设$C\boldsymbol{x} &#x3D; \lambda \boldsymbol{x}$，那么我们只需要找到一个特征向量$\boldsymbol{x}’$，满足$A\boldsymbol{x}’ &#x3D; \lambda\boldsymbol{x}’$。注意到，当$\boldsymbol{x}’ &#x3D; B\boldsymbol{x}$，有<br>$$<br>AB\boldsymbol{x} &#x3D; BCB^{-1}B\boldsymbol{x} &#x3D; BC\boldsymbol{x} &#x3D; \lambda B\boldsymbol{x}<br>$$<br>因此，$A$与$C$的特征值相同。</p>
</blockquote>
<h3 id="矩阵的幂"><a href="#矩阵的幂" class="headerlink" title="矩阵的幂"></a>矩阵的幂</h3><p>对于形如$\boldsymbol{u}<em>{k + 1} &#x3D; A\boldsymbol{u}</em>{k}$的方程，我们下面说明使用对角化求解的方法：</p>
<ol>
<li><p>通过递推关系，我们可以得到$\boldsymbol{u}<em>{k} &#x3D; A^{k}\boldsymbol{u}</em>{0}$。而通过对角化我们可以得到<br>$$<br>\boldsymbol{u}<em>{k} &#x3D; X\Lambda^{k} X^{-1}\boldsymbol{u}</em>{0}<br>$$</p>
</li>
<li><p>对于$n\times n$矩阵$A$，由于$X$为可逆矩阵，因此其列向量（也就是特征向量）可以张成$\boldsymbol{R}^{n}$。同时由于$\boldsymbol{u}<em>{0}$为$n\times 1$向量，因此我们可以将其写为特征向量的线性组合<br>$$<br>\boldsymbol{u}</em>{0} &#x3D; \sum\limits_{i &#x3D; 1}^{n}c_{i}\boldsymbol{x}<em>{i} \longrightarrow X\boldsymbol{c} &#x3D; \boldsymbol{u}</em>{0} \longrightarrow \boldsymbol{c} &#x3D; X^{-1}\boldsymbol{u}_{0}<br>$$</p>
</li>
<li><p>两边同时左乘$X\Lambda^{k}$可以得到<br>$$<br>\boldsymbol{u}<em>{k} &#x3D; X\Lambda^{k} \boldsymbol{c} &#x3D; \sum\limits</em>{i &#x3D; 1}^{n}c_{i}(\lambda_{i})^{k}\boldsymbol{x}_{i}<br>$$</p>
</li>
</ol>
<h3 id="非对角化矩阵"><a href="#非对角化矩阵" class="headerlink" title="非对角化矩阵"></a>非对角化矩阵</h3><p>并不是每个特征向量对应的特征值相同。因此，对于一个特定特征值$\lambda$，我们按照如下方式定义两种多重度：</p>
<ol>
<li><p>几何多重度：$\lambda$对应的特征向量中，线性无关的特征向量数量</p>
</li>
<li><p>代数多重度：$\lambda$对应几个特征向量（或者说$\lambda$的重复次数）</p>
</li>
</ol>
<p>此时，我们将对角化条件表述如下：</p>
<blockquote>
<p>定理：</p>
<p>当几何多重度小于代数多重度时，矩阵$A$不可对角化。</p>
</blockquote>
<h2 id="对称矩阵"><a href="#对称矩阵" class="headerlink" title="对称矩阵"></a>对称矩阵</h2><h3 id="摘要-17"><a href="#摘要-17" class="headerlink" title="摘要"></a>摘要</h3><ol>
<li><p>假设矩阵$S$为对称矩阵，那么其有$n$个实特征值$\lambda_{i}$，并且有$n$个正交的特征向量$q_{i}$</p>
</li>
<li><p>每个实对称矩阵都可以对角化，即$S &#x3D; Q\Lambda Q^{-1} &#x3D; Q\Lambda Q^{\mathrm{T}}$（此时$Q$为正交矩阵）</p>
</li>
<li><p>$S$的正特征值的数量与正的主元的数量相同</p>
</li>
<li><p>反对称矩阵满足$A &#x3D; -A^{\mathrm{T}}$，其有虚特征值$\lambda$和正交的复特征向量$\boldsymbol{q}$</p>
</li>
</ol>
<h3 id="引入-6"><a href="#引入-6" class="headerlink" title="引入"></a>引入</h3><p>对于对称矩阵$S$，将其对角化时有$S &#x3D; X\Lambda X^{-1}$。取转置可得$S^{\mathrm{T}} &#x3D; (X^{-1})^{\mathrm{T}}\Lambda X^{\mathrm{T}}$。由于$S &#x3D; S^{\mathrm{T}}$，因此我们可得<br>$$<br>X\Lambda X^{-1} &#x3D; (X^{-1})^{\mathrm{T}}\Lambda X^{\mathrm{T}} \longrightarrow X^{\mathrm{T}} &#x3D; X^{-1} \longrightarrow X^{\mathrm{T}} X &#x3D; I<br>$$<br>此时，通过将$X$中的向量变为单位向量，我们可以将$X$变为正交矩阵$Q$。</p>
<p>下面我们证明一个定理：</p>
<blockquote>
<p>定理：</p>
<p>实对称矩阵的每个特征值都是实数</p>
</blockquote>
<blockquote>
<p>证明：</p>
<p>假设$S\boldsymbol{x} &#x3D; \lambda\boldsymbol{x}$中的特征值与特征向量均为复数，此时有<br>$$<br>S\overline{\boldsymbol{x}} &#x3D; \overline{\lambda}\overline{\boldsymbol{x}} \longrightarrow \overline{\boldsymbol{x}}^{\mathrm{T}} S &#x3D; \overline{\boldsymbol{x}}^{\mathrm{T}}\overline{\lambda} \longrightarrow \overline{\boldsymbol{x}}^{\mathrm{T}} S \boldsymbol{x} &#x3D; \overline{\boldsymbol{x}}^{\mathrm{T}}\overline{\lambda} \boldsymbol{x}<br>$$<br>将$S\boldsymbol{x} &#x3D; \lambda\boldsymbol{x}$两边同时左乘$\overline{\boldsymbol{x}}^{\mathrm{T}}$可得$\overline{\boldsymbol{x}}^{\mathrm{T}} S\boldsymbol{x} &#x3D; \overline{\boldsymbol{x}}^{\mathrm{T}} \lambda\boldsymbol{x}$。将两个方程联系起来不难得到<br>$$<br>\overline{\boldsymbol{x}}^{\mathrm{T}}\overline{\lambda} \boldsymbol{x} &#x3D; \overline{\boldsymbol{x}}^{\mathrm{T}} \lambda\boldsymbol{x}<br>$$<br>这表明$\overline{\lambda} &#x3D; \lambda$，即$\lambda \in \mathbb{R}$</p>
</blockquote>
<p>由于对称矩阵可以表示为$S &#x3D; Q\Lambda Q^{\mathrm{T}}$，因此其可以写为$S &#x3D; \sum\limits_{i &#x3D; 1}^{n}\lambda_{i}\boldsymbol{q}_{i}\boldsymbol{q}^{\mathrm{T}}$</p>
<h3 id="特征值与主元"><a href="#特征值与主元" class="headerlink" title="特征值与主元"></a>特征值与主元</h3><p>对于对称矩阵，我们可以得到如下关系<br>$$<br>\det S &#x3D; \det Q\det \Lambda \det Q^{\mathrm{T}} &#x3D; \det \Lambda<br>$$<br>因此不难看出，对称矩阵的主元之积等于其特征值之积，二者的符号自然相同。因此，正特征值的数量与正主元数量相同。（这个关系是否对于任意可以对角化的矩阵成立？）</p>
<p>任意一个矩阵都可以按照LDU分解。对于对称矩阵，由于$S &#x3D; S^{\mathrm{T}}$，因此<br>$$<br>LDU &#x3D; U^{\mathrm{T}} DL^{\mathrm{T}}<br>$$<br>不难看出，此时$U &#x3D; L^{\mathrm{T}}$。代入LDU分解可得 $S &#x3D; LDL^{\mathrm{T}}$</p>
<h2 id="正定矩阵"><a href="#正定矩阵" class="headerlink" title="正定矩阵"></a>正定矩阵</h2><h3 id="摘要-18"><a href="#摘要-18" class="headerlink" title="摘要"></a>摘要</h3><ol>
<li><p>对于$\forall\boldsymbol{x} \in \boldsymbol{R}^{n}$且$\boldsymbol{x} \neq 0$，如果$\boldsymbol{x}^{\mathrm{T}} S\boldsymbol{x} &gt; 0$，那么我们称$S$为正定矩阵（Positive Definite Matrix）。</p>
</li>
<li><p>如果矩阵$S$可以写为$S &#x3D; A^{\mathrm{T}} A$，其中$A$的列向量线性无关，那么其为正定矩阵。</p>
</li>
<li><p>对于$\forall\boldsymbol{x} \in \boldsymbol{R}^{n}$且$\boldsymbol{x} \neq 0$，如果$\boldsymbol{x}^{\mathrm{T}} S\boldsymbol{x} \geq 0$，那么我们称$S$为半正定矩阵（Positive Semi-definite Matrix）。</p>
</li>
<li><p>对于正定矩阵$S$，$\boldsymbol{x}^{\mathrm{T}} S\boldsymbol{x} &#x3D; 1$给出了一个$\boldsymbol{R}^{n}$中的椭球。</p>
</li>
</ol>
<h3 id="正定的定义"><a href="#正定的定义" class="headerlink" title="正定的定义"></a>正定的定义</h3><blockquote>
<p>定理：</p>
<p>如果$A$的列向量线性无关，那么$S &#x3D; A^{\mathrm{T}} A$为正定矩阵 </p>
</blockquote>
<blockquote>
<p>证明：</p>
<p>对于$\forall\boldsymbol{x} \in \boldsymbol{R}^{n}$，我们有$\boldsymbol{x}^{\mathrm{T}} S\boldsymbol{x} &#x3D; \boldsymbol{x}^{\mathrm{T}} A^{\mathrm{T}} A\boldsymbol{x}$。不难看出，后面的表达式实际上为$||A\boldsymbol{x}||^{2}$。由于$\boldsymbol{x} \neq 0$，因此$||A\boldsymbol{x}|| &gt; 0$。</p>
</blockquote>
<h3 id="半正定矩阵"><a href="#半正定矩阵" class="headerlink" title="半正定矩阵"></a>半正定矩阵</h3><p>半正定矩阵指的是满足$\boldsymbol{x}^{\mathrm{T}} S\boldsymbol{x} \geq 0$的矩阵。其也可以分解为$A^{\mathrm{T}} A$的形式，只不过此时$A$的列向量线性相关。</p>
<h1 id="奇异值分解"><a href="#奇异值分解" class="headerlink" title="奇异值分解"></a>奇异值分解</h1><h2 id="奇异值分解中的基和矩阵"><a href="#奇异值分解中的基和矩阵" class="headerlink" title="奇异值分解中的基和矩阵"></a>奇异值分解中的基和矩阵</h2><h3 id="摘要-19"><a href="#摘要-19" class="headerlink" title="摘要"></a>摘要</h3><ol>
<li><p>奇异值分解（Singular Value Decomposition, SVD）使得四个子空间（行空间、零空间、列空间和剩余零空间）的基均为正交基</p>
</li>
<li><p>使用这些基向量，矩阵$A$变为对角矩阵$\Sigma$，并且$A\boldsymbol{v}<em>{i} &#x3D; \sigma\boldsymbol{u}</em>{i}$，其中$\sigma_{i}$为奇异值 </p>
</li>
<li><p>奇异值分解$A &#x3D; U\Sigma V^{\mathrm{T}}$使得$A$变为许多秩一矩阵的和，即$A &#x3D; \sum\limits_{i &#x3D; 1}^{r}\sigma_{i}\boldsymbol{u}<em>{i}\boldsymbol{v}</em>{i}^{\mathrm{T}}$。并且$\sigma_{1}\boldsymbol{u}<em>{1}\boldsymbol{v}</em>{1}^{\mathrm{T}}$为最大的。</p>
</li>
</ol>
<h3 id="引入-7"><a href="#引入-7" class="headerlink" title="引入"></a>引入</h3><p>之所以使用奇异值分解，而非对角化，是因为$A &#x3D; X\Lambda X^{-1}$这种对角化并非对于所有矩阵都成立，而奇异值分解却对于任意$M \times n$矩阵$A$均存在。</p>
<p>为了完成SVD分解，我们需要引入两组奇异向量（Singular Vectors），记为$\boldsymbol{u}$和$\boldsymbol{v}$。其中，$\boldsymbol{u}<em>{i} \in \boldsymbol{R}^{m}$而$\boldsymbol{v}</em>{i} \in \boldsymbol{R}^{n}$。它们与四个子空间的对应关系如下所示：</p>
<ol>
<li><p>$\boldsymbol{u}<em>{1},\ \dots,\ \boldsymbol{u}</em>{r}$为列空间的正交基</p>
</li>
<li><p>$\boldsymbol{u}<em>{r + 1},\ \dots,\ \boldsymbol{u}</em>{m}$为剩余零空间的正交基</p>
</li>
<li><p>$\boldsymbol{v}<em>{1},\ \dots,\ \boldsymbol{v}</em>{r}$为行空间的正交基</p>
</li>
<li><p>$\boldsymbol{v}<em>{r + 1},\ \dots,\ \boldsymbol{v}</em>{n}$为零空间的正交基</p>
</li>
</ol>
<p>此时，这些向量满足如下关系<br>$$<br>A\boldsymbol{v}<em>{i} &#x3D; \sigma</em>{i}\boldsymbol{u}<em>{i} i \in [1,\ r]<br>$$<br>其中，$\sigma</em>{i}$被称为奇异值。对于一个特征方程$A\boldsymbol{x} &#x3D; \lambda\boldsymbol{x}$，我们不难看出<br>$$<br>||A\boldsymbol{x}|| &#x3D; ||\lambda \boldsymbol{x}|| &#x3D; |\lambda|\ ||\boldsymbol{x}||<br>$$<br>当特征向量为正交向量$\boldsymbol{v}<em>{i}$（此时也是单位向量），上式变为<br>$$<br>||A\boldsymbol{v}</em>{i}|| &#x3D; |\lambda_{i}|<br>$$<br>这表示在$A$的作用下，$\boldsymbol{v}<em>{i}$被拉长（或者反向拉长）的程度。因此，我们可以说$A$的奇异值$\sigma</em>{i}$为$A\boldsymbol{v}_{i}$的长度（之所以为奇异值为正值，是因为规定如此）。</p>
<p>我们可以将上式写为如下的矩阵形式<br>$$<br>AV_{r} &#x3D; U_{r}\Sigma_{r} \longleftrightarrow A\begin{bmatrix}<br>\boldsymbol{v}<em>{1} &amp; \boldsymbol{v}</em>{2} &amp; \dots &amp; \boldsymbol{v}<em>{r}\<br>\end{bmatrix} &#x3D; \begin{bmatrix}<br>\boldsymbol{u}</em>{1} &amp; \boldsymbol{u}<em>{2} &amp; \dots &amp; \boldsymbol{u}</em>{r} \<br>\end{bmatrix} \begin{bmatrix}<br>\sigma_{1} &amp; 0 &amp; \dots &amp; 0 \<br>0 &amp; \sigma_{2} &amp; \dots &amp; 0 \<br>\vdots &amp; \vdots &amp;  &amp; \vdots \<br>0 &amp; 0 &amp; \dots &amp; \sigma_{r} \<br>\end{bmatrix}<br>$$<br>由于$\boldsymbol{v}<em>{r + 1}$到$\boldsymbol{v}</em>{n}$为零空间的正交基向量，我们可以得到$A\boldsymbol{v}<em>{i} &#x3D; 0,\ i \in [r + 1,\ n]$。由此不难得到<br>$$<br>AV &#x3D; U\Sigma \longleftrightarrow A\begin{bmatrix}<br>V</em>{r} &amp; V_{n - r} \<br>\end{bmatrix} &#x3D; \begin{bmatrix}<br>U_{r} &amp; U_{n - r} \<br>\end{bmatrix} \begin{bmatrix}<br>\Sigma_{r} &amp; 0 \<br>0 &amp; 0 \<br>\end{bmatrix}<br>$$<br>由于$V$为正交向量组成的矩阵，因此$V^{-1} &#x3D; V^{\mathrm{T}}$。由此我们可以得到$A &#x3D; U\Sigma V^{\mathrm{T}}$。由这个式子，我们也可以将$A$表示为秩一矩阵之和，即$A &#x3D; \sum\limits_{i &#x3D; 1}^{r}\sigma_{i}\boldsymbol{u}<em>{i}\boldsymbol{v}</em>{i}^{\mathrm{T}}$</p>
<p>当$A$为正定矩阵（或半正定矩阵）时，奇异值分解与对角化相同（$U &#x3D; V &#x3D; X$）</p>
<h3 id="SVD的证明"><a href="#SVD的证明" class="headerlink" title="SVD的证明"></a>SVD的证明</h3><p>下面说明几个定理</p>
<blockquote>
<p>定理：</p>
<p>$\boldsymbol{v}_{i}$为$A^{\mathrm{T}} A$的正交特征向量，$\Sigma^{\mathrm{T}}\Sigma$为特征值矩阵。</p>
</blockquote>
<blockquote>
<p>证明：</p>
<p>$$<br>A^{\mathrm{T}} A &#x3D; (U\Sigma V^{\mathrm{T}})^{\mathrm{T}}(U\Sigma V^{\mathrm{T}}) &#x3D; V\Sigma^{\mathrm{T}} \Sigma V^{\mathrm{T}}<br>$$<br>由于$A^{\mathrm{T}} A$为正定矩阵（或半正定矩阵），同时也是对称矩阵，并且$\boldsymbol{v}_{i}$为正交向量，因此$V$为正交矩阵，从而$V$为$A^{\mathrm{T}} A$的特征向量矩阵。同理，由于对称矩阵的对角化可以写为<br>$$<br>S &#x3D; Q\Lambda Q^{\mathrm{T}}<br>$$<br>因此$\Sigma^{\mathrm{T}}\Sigma$为特征值矩阵。</p>
</blockquote>
<p>通过上面的证明，我们可以看出，$A^{\mathrm{T}} A$的特征值为$\sigma_{i}^{2}$。换言之，$A^{\mathrm{T}} A$的特征值的平方根为奇异值。</p>
<h3 id="奇异值分解的计算过程"><a href="#奇异值分解的计算过程" class="headerlink" title="奇异值分解的计算过程"></a>奇异值分解的计算过程</h3><ol>
<li><p>将矩阵$A^{\mathrm{T}} A$对角化</p>
</li>
<li><p>计算$V\Sigma$：先通过对角化的$A^{\mathrm{T}} A$的特征值计算出奇异值，然后将其对应的正交向量求出</p>
</li>
<li><p>构造$U$：$U_{r}$为从$AV_{r}$计算得到的单位向量，然后将其扩展为单位正交基。</p>
</li>
</ol>
<h2 id="SVD的几何意义"><a href="#SVD的几何意义" class="headerlink" title="SVD的几何意义"></a>SVD的几何意义</h2><h3 id="摘要-20"><a href="#摘要-20" class="headerlink" title="摘要"></a>摘要</h3><ol>
<li><p>奇异值分解$A &#x3D; U\Sigma V^{\mathrm{T}}$可以视为旋转矩阵<em>拉伸矩阵</em>旋转矩阵</p>
</li>
<li><p>$A$可以将圆上的向量$\boldsymbol{x}$变为椭圆上的向量$A\boldsymbol{x}$</p>
</li>
<li><p>矩阵$A$的范数为$||A|| &#x3D; \sigma_{1}$，其中$\sigma_{1}$为最大的奇异值</p>
</li>
<li><p>矩阵$A$的极分解为$A &#x3D; QS$，其中$Q &#x3D; UV^{\mathrm{T}}$为旋转矩阵，$S &#x3D; V\Sigma V^{\mathrm{T}}$为拉伸矩阵</p>
</li>
<li><p>矩阵$A$的伪逆（Pesudoinverse）为$A^{+} &#x3D; V\Sigma^{+}U^{\mathrm{T}}$，其将列空间中的向量$A\boldsymbol{x}$重新代入行空间中的$\boldsymbol{x}$</p>
</li>
</ol>
<h3 id="矩阵的范数"><a href="#矩阵的范数" class="headerlink" title="矩阵的范数"></a>矩阵的范数</h3><p>矩阵的范数就是矩阵最大的奇异值。其满足以下两个不等式 </p>
<ol>
<li><p>$||A + B|| \leq ||A|| + ||B||$</p>
</li>
<li><p>$||AB|| \leq ||A||\ ||B||$</p>
</li>
</ol>
<blockquote>
<p>Eckart-Young-Mirsky定理：在秩为$k$的矩阵中，最接近$A$的矩阵$A_{k}$满足<br>$$<br>A_{k} &#x3D; \sum\limits_{i &#x3D; 1}^{k} \sigma_{i}\boldsymbol{u}<em>{i}\boldsymbol{v}</em>{i}^{\mathrm{T}}<br>$$<br>换言之，对于任意秩为$k$的矩阵$B$，有<br>$$<br>||A - B|| \geq ||A - A_{k}||<br>$$</p>
</blockquote>
<h3 id="极分解-A-QS"><a href="#极分解-A-QS" class="headerlink" title="极分解$A &#x3D; QS$"></a>极分解$A &#x3D; QS$</h3><p>由于每个矩阵都能进行奇异值分解，因此每个矩阵都能进行极分解<br>$$<br>A &#x3D; QS &#x3D; (UV^{\mathrm{T}})(V\Sigma V^{\mathrm{T}})<br>$$<br>由于$Q$为方阵，且$Q^{\mathrm{T}} Q &#x3D; VU^{\mathrm{T}} UV^{\mathrm{T}} &#x3D; I$，因此$Q$为正交矩阵。同时，不难看出$S &#x3D; V\Sigma V^{\mathrm{T}}$为将$S$对角化为$\Sigma$的形式，因此$S$的特征值为$A^{\mathrm{T}} A$的奇异值。同时有$S^{2} &#x3D; V\Sigma^{2}V^{\mathrm{T}} &#x3D; A^{\mathrm{T}} A$。</p>
<p>QS分解也可写为KQ分解，即<br>$$<br>A &#x3D; KQ &#x3D; (U\Sigma U^{\mathrm{T}})(UV^{\mathrm{T}})<br>$$</p>
<h3 id="伪逆"><a href="#伪逆" class="headerlink" title="伪逆"></a>伪逆</h3><p>如果$A\boldsymbol{v} &#x3D; \sigma\boldsymbol{u}$，那么在$A^{-1}$存在时，$A^{-1}\boldsymbol{u} &#x3D; \dfrac{\boldsymbol{v}}{\sigma}$。但无论$A^{-1}$是否存在，如果我们将$A^{+}$右乘$\boldsymbol{u}$，那么我们总是可以得到$\dfrac{\boldsymbol{v}}{\sigma}$。伪逆的定义为<br>$$<br>A^{+} &#x3D; V\Sigma^{+}U^{\mathrm{T}} &#x3D; \begin{bmatrix}<br>\boldsymbol{v}<em>{1} &amp; \boldsymbol{v}</em>{2} &amp; \dots &amp; \boldsymbol{v}<em>{n} \<br>\end{bmatrix} \begin{bmatrix}<br>\sigma</em>{1}^{-1} &amp;  &amp;  &amp; \<br> &amp; \ddots &amp; &amp; \<br> &amp;  &amp; \sigma_{r}^{-1} &amp; \<br> &amp;  &amp;  &amp; 0 \<br>\end{bmatrix} \begin{bmatrix}<br>\boldsymbol{u}<em>{1}^{\mathrm{T}} \<br>\boldsymbol{u}</em>{2}^{\mathrm{T}} \<br>\vdots \<br>\boldsymbol{u}<em>{m}^{\mathrm{T}} \<br>\end{bmatrix}<br>$$<br>如果$A$可逆，那么$A^{-1} &#x3D; A^{+}$。但当$A$不满秩时，将$\boldsymbol{u}</em>{i}$左乘伪逆可以得到以下结果<br>$$<br>A^{+}\boldsymbol{u}<em>{i} &#x3D; \left {<br>\begin{aligned}<br>&amp; \dfrac{\boldsymbol{v}</em>{i}}{\sigma_{i}},  i \leq r \<br>&amp; 0,  i &gt; r \<br>\end{aligned}<br>\right.<br>$$<br>譬如，对于$\boldsymbol{u}<em>{1}$我们有<br>$$<br>\begin{bmatrix}<br>\boldsymbol{v}</em>{1} &amp; \boldsymbol{v}<em>{2} &amp; \dots &amp; \boldsymbol{v}</em>{n} \<br>\end{bmatrix} \begin{bmatrix}<br>\sigma_{1}^{-1} &amp;  &amp;  &amp; \<br> &amp; \ddots &amp; &amp; \<br> &amp;  &amp; \sigma_{r}^{-1} &amp; \<br> &amp;  &amp;  &amp; 0 \<br>\end{bmatrix} \begin{bmatrix}<br>\boldsymbol{u}<em>{1}^{\mathrm{T}} \<br>\boldsymbol{u}</em>{2}^{\mathrm{T}} \<br>   \vdots \<br>\boldsymbol{u}<em>{m}^{\mathrm{T}} \<br>\end{bmatrix} \boldsymbol{u}</em>{1} &#x3D; \begin{bmatrix}<br>\boldsymbol{v}<em>{1} &amp; \boldsymbol{v}</em>{2} &amp; \dots &amp; \boldsymbol{v}<em>{n} \<br>\end{bmatrix} \begin{bmatrix}<br>\sigma</em>{1}^{-1} &amp;  &amp;  &amp; \<br> &amp; \ddots &amp; &amp; \<br> &amp;  &amp; \sigma_{r}^{-1} &amp; \<br> &amp;  &amp;  &amp; 0 \<br>\end{bmatrix} \begin{bmatrix}<br>1\<br>0\<br>\vdots \<br>0\<br>\end{bmatrix}<br>$$<br>由此可得<br>$$<br>\begin{bmatrix}<br>\boldsymbol{v}<em>{1} &amp; \boldsymbol{v}</em>{2} &amp; \dots &amp; \boldsymbol{v}<em>{n} \<br>\end{bmatrix} \begin{bmatrix}<br>\sigma</em>{1}^{-1}\<br>0\<br>\vdots \<br>0\<br>\end{bmatrix} &#x3D; \sigma_{1}^{-1}\boldsymbol{v}_{1}<br>$$</p>
<p>对于伪逆有以下定理：</p>
<blockquote>
<p>证明：对于$\forall \boldsymbol{b}\in \boldsymbol{R}^{m}$，$\exists \boldsymbol{x}^{+} \in \boldsymbol{C}(A^{\mathrm{T}})$，使得$A^{+}\boldsymbol{b} &#x3D; \boldsymbol{x}^{+}$</p>
<p>由于$\boldsymbol{C}(A)$与$\boldsymbol{N}(A^{\mathrm{T}})$正交，因此总是存在唯一的分解方式，使得$A^{+}\boldsymbol{b}$可以分解为$A^{+}\boldsymbol{p} + A^{+}\boldsymbol{e}$，其中$\boldsymbol{p} \in \boldsymbol{C}(A)$，而$\boldsymbol{e} \in \boldsymbol{N}(A^{\mathrm{T}})$。下面我们说明两个问题：</p>
<ol>
<li><p>$\exists \boldsymbol{x}^{+} \in \boldsymbol{C}(A^{\mathrm{T}})$，使得$A^{+}\boldsymbol{p} &#x3D; \boldsymbol{x}^{+}$</p>
</li>
<li><p>$A^{+}\boldsymbol{e} &#x3D; 0$</p>
</li>
</ol>
<p>对于第一个问题，假设$\boldsymbol{x}^{+} &#x3D; \boldsymbol{x}<em>{\mathrm{row}} + \boldsymbol{x}</em>{\mathrm{null}}$，其中$\boldsymbol{x}<em>{\mathrm{row}} \in \boldsymbol{C}(A^{\mathrm{T}})$，而$\boldsymbol{x}</em>{\mathrm{null}} \in \boldsymbol{N}(A^{\mathrm{T}})$，那么<br>$$<br>AA^{+} \boldsymbol{x}^{+} &#x3D; A\boldsymbol{x}<em>{\mathrm{row}} + A\boldsymbol{x}</em>{\mathrm{null}} &#x3D; A\boldsymbol{x}<em>{\mathrm{row}}<br>$$<br>这表明，$A^{+}\boldsymbol{x}^{+} &#x3D; \boldsymbol{x}</em>{\mathrm{row}}$。因此$\boldsymbol{x}^{+}$必然在行空间中。</p>
<p>对于第二个问题，由于$\boldsymbol{e} \in \boldsymbol{N}(A^{\mathrm{T}})$，因此<br>$$<br>\boldsymbol{e} &#x3D; \begin{bmatrix}<br>\boldsymbol{u}<em>{r + 1} &amp; \dots &amp; \boldsymbol{u}</em>{m} \<br>\end{bmatrix} \begin{bmatrix}<br>c_{r + 1} \ \dots \ c_{m}\<br>\end{bmatrix}<br>$$<br>由此不难得到<br>$$<br>A^{+} \boldsymbol{e} &#x3D; A\begin{bmatrix}<br>\boldsymbol{u}<em>{r + 1} &amp; \dots &amp; \boldsymbol{u}</em>{m} \<br>\end{bmatrix} \begin{bmatrix}<br>c_{r + 1} \ \dots \ c_{m}\<br>\end{bmatrix} &#x3D; 0<br>$$<br>注意当$i \in [r + 1,\ m]$时，$A\boldsymbol{u}_{i} &#x3D; 0$。</p>
</blockquote>
<p>由于$\forall \boldsymbol{x} \in \boldsymbol{R}^{n}$，$\exists \boldsymbol{b} \in \boldsymbol{C}(A)$，使得$A\boldsymbol{x} &#x3D; \boldsymbol{b}$，因此我们可以这样说</p>
<blockquote>
<p>推论：</p>
<p>线性映射$A$将$\boldsymbol{R}^{n}$中属于$\boldsymbol{C}(A^{\mathrm{T}})$的部分映射到$\boldsymbol{C}(A)$，将$\boldsymbol{N}(A)$的部分映射到0；线性映射$A^{+}$将$\boldsymbol{R}^{m}$中属于$\boldsymbol{C}(A)$的部分映射到$\boldsymbol{C}(A^{\mathrm{T}})$，将$\boldsymbol{N}(A^{\mathrm{T}})$的部分映射到0</p>
</blockquote>
<h1 id="线性变换"><a href="#线性变换" class="headerlink" title="线性变换"></a>线性变换</h1><h2 id="线性变换的概念"><a href="#线性变换的概念" class="headerlink" title="线性变换的概念"></a>线性变换的概念</h2><h3 id="摘要-21"><a href="#摘要-21" class="headerlink" title="摘要"></a>摘要</h3><ol>
<li><p>线性变换$T$将向量$\boldsymbol{v}$变为$T(\boldsymbol{v})$，其中“线性”要求$T(c\boldsymbol{v} + d\boldsymbol{w}) &#x3D; cT(\boldsymbol{v}) + dT(\boldsymbol{w})$。</p>
</li>
<li><p>线性变换$T$满足$T(\boldsymbol{0}) &#x3D; \boldsymbol{0}$</p>
</li>
<li><p>$\boldsymbol{v}$和$T(\boldsymbol{v})$可以在$\boldsymbol{R}^{n}$中，或者矩阵空间中，亦或是函数空间中</p>
</li>
<li><p>求导$T(f) &#x3D; \dfrac{\mathrm{d} f}{\mathrm{d} x}$为线性变换，而积分$\displaystyle T^{+}(f) &#x3D; \int_{0}^{x} f(t) \mathrm{d} t$为其伪逆</p>
</li>
<li><p>两个线性变换的积仍然为线性变换，即$(ST)(\boldsymbol{v}) &#x3D; S(T(\boldsymbol{v}))$</p>
</li>
</ol>
<h3 id="引入-8"><a href="#引入-8" class="headerlink" title="引入"></a>引入</h3><p>线性变换与平移组合得到的变换$T(\boldsymbol{v}) &#x3D; A\boldsymbol{v} + \boldsymbol{u}_{0}$被称为仿射变换（Affine Transformation）</p>
<h3 id="线性变换与基"><a href="#线性变换与基" class="headerlink" title="线性变换与基"></a>线性变换与基</h3><p>由于线性变换的“线性”，基经过变换后得到的向量组为变换后空间的基。</p>
<h3 id="线性变换的像与核"><a href="#线性变换的像与核" class="headerlink" title="线性变换的像与核"></a>线性变换的像与核</h3><p>线性变换的像（Range&#x2F;Image）指的是线性变换$T$的所有像$T(\boldsymbol{v})$组成的空间</p>
<p>线性变换的核（Kernel）指的是所有使得线性变换$T$的像为0的原像$\boldsymbol{v}$，即$T(\boldsymbol{v}) &#x3D; 0$</p>
<h2 id="线性变换的矩阵"><a href="#线性变换的矩阵" class="headerlink" title="线性变换的矩阵"></a>线性变换的矩阵</h2><h3 id="摘要-22"><a href="#摘要-22" class="headerlink" title="摘要"></a>摘要</h3><ol>
<li><p>如果我们知道原空间的基向量$\boldsymbol{v}<em>{i}$，那么通过线性变换，我们能够得到新空间的基向量$T(\boldsymbol{v}</em>{i})$</p>
</li>
<li><p>通过将线性变换$T$作用在基向量$\boldsymbol{v}_{j}$上，我们能够得到$T$对应的矩阵中的第$j$列</p>
</li>
</ol>
<h3 id="基的变换"><a href="#基的变换" class="headerlink" title="基的变换"></a>基的变换</h3><p>假如$\boldsymbol{V} &#x3D; \boldsymbol{W} &#x3D; \boldsymbol{R}^{2}$，并且线性变换$T(\boldsymbol{v}) &#x3D; \boldsymbol{v}$，同时假设$\boldsymbol{v}<em>{1}$和$\boldsymbol{v}</em>{2}$为$\boldsymbol{V}$的基向量，而$\boldsymbol{w}<em>{1}$和$\boldsymbol{w}</em>{2}$为$\boldsymbol{W}$的基向量，那么此时我们可以将线性变换的结果<br>$T(\boldsymbol{v}<em>{1})$和$T(\boldsymbol{v}</em>{2})$写为$\boldsymbol{w}<em>{1}$和$\boldsymbol{w}</em>{2}$的线性组合，即<br>$$<br>\begin{bmatrix}<br>\boldsymbol{w}<em>{1} &amp; \boldsymbol{w}</em>{2} \<br>\end{bmatrix} \begin{bmatrix}<br>b_{11} &amp; b_{12} \<br>b_{21} &amp; b_{22} \<br>\end{bmatrix} &#x3D; \begin{bmatrix}<br>\boldsymbol{v}<em>{1} &amp; \boldsymbol{v}</em>{2} \<br>\end{bmatrix}<br>$$<br>由此不难看出，如果我们从同一个空间的一组基$V$换为另一组基$W$，那么二者满足$WB &#x3D; V$，或者说$B &#x3D; W^{-1}V$。此时，对于$\forall \boldsymbol{u} \in \boldsymbol{R}^{2}$，有<br>$$<br>\boldsymbol{u} &#x3D; V\boldsymbol{c} &#x3D; W\boldsymbol{d}<br>$$<br>由于此时$V$和$W$是基向量组成的矩阵，因此我们可以称$\boldsymbol{c}$和$\boldsymbol{d}$分别为这两个基下的坐标。不难看出，此时这两个坐标之间满足<br>$$<br>\boldsymbol{d} &#x3D; W^{-1}V\boldsymbol{c} &#x3D; B\boldsymbol{c}<br>$$<br>此时我们称矩阵$B$为由基$\boldsymbol{v}<em>{i}$向$\boldsymbol{w}</em>{i}$变换的坐标变换矩阵。</p>
<h3 id="构造矩阵"><a href="#构造矩阵" class="headerlink" title="构造矩阵"></a>构造矩阵</h3><p>假如此时$T$将$n$维空间$\boldsymbol{V}$转变为$m$维空间$\boldsymbol{W}$，并且$\boldsymbol{V}$的基为$\boldsymbol{v}<em>{i}$，$\boldsymbol{W}$的基为$\boldsymbol{w}</em>{i}$，那么我们所需的矩阵自然为$m\times n$的矩阵。不难想到，对于基向量$\boldsymbol{v}<em>{j}$，其线性变换后得到<br>$$<br>T(\boldsymbol{v}</em>{j}) &#x3D; \sum\limits_{i &#x3D; 1}^{m} a_{ij}\boldsymbol{w}<em>{i}<br>$$<br>这样，对于$\forall \boldsymbol{u} \in \boldsymbol{V}$，将线性变换作用于其上可以得到<br>$$<br>T(\boldsymbol{u}) &#x3D; \sum\limits</em>{j &#x3D; 1}^{n}c_{j}T(\boldsymbol{v}<em>{j}) &#x3D; \begin{bmatrix}<br>T(\boldsymbol{v}</em>{1}) &amp; T(\boldsymbol{v}<em>{2}) &amp; \dots &amp; T(\boldsymbol{v}</em>{n}) \<br>\end{bmatrix} \begin{bmatrix}<br>c_{1} \ c_{2} \ \vdots \ c_{n} \<br>\end{bmatrix}<br>$$<br>结合上式不难得到<br>$$<br>T(\boldsymbol{u}) &#x3D; \begin{bmatrix}<br>\boldsymbol{w}<em>{1} &amp; \boldsymbol{w}</em>{2} &amp; \dots &amp; \boldsymbol{w}<em>{m} \<br>\end{bmatrix} \begin{bmatrix}<br>a</em>{11} &amp; a_{12} &amp; \dots &amp; a_{1n} \<br>a_{21} &amp; a_{22} &amp; \dots &amp; a_{2n} \<br>\vdots &amp; \vdots &amp;  &amp; \vdots \<br>a_{m1} &amp; a_{m2} &amp; \dots &amp; a_{mn} \<br>\end{bmatrix} \begin{bmatrix}<br>c_{1} \ c_{2} \ \vdots \ c_{n} \<br>\end{bmatrix} &#x3D; WM\boldsymbol{c}<br>$$<br>可以看到，此时$M\boldsymbol{c}$表示$T(\boldsymbol{u})$在新的基下的坐标。如果我们用左乘矩阵$M’$来表示线性变换$T$的效果（也就是$T(\boldsymbol{u}) &#x3D; M’\boldsymbol{u}$），那么<br>$$<br>T(\boldsymbol{u}) &#x3D; M’V\boldsymbol{c} &#x3D; WM\boldsymbol{c} &#x3D; W\boldsymbol{d}<br>$$<br>这表明，此时线性变换$T(\boldsymbol{u})$对应的矩阵为<br>$$<br>M’ &#x3D; WMV^{-1}<br>$$<br>同时，我们也可以说，此时变换矩阵变为<br>$$<br>M &#x3D; W^{-1} M’ V<br>$$</p>
<p>当我们给定原始坐标$\boldsymbol{c}$时，通过左乘$M$，我们能够得到新的坐标$\boldsymbol{d} &#x3D; M\boldsymbol{c}$。此时$M$也可以写成<br>$$<br>M &#x3D; \begin{bmatrix}<br>[T(\boldsymbol{v}<em>{1})]</em>{w} &amp; [T(\boldsymbol{v}<em>{2})]</em>{w} &amp; \dots &amp; [T(\boldsymbol{v}<em>{n})]</em>{w} \<br>\end{bmatrix}<br>$$<br>也就是说，此时$M$的第$i$列为$T(\boldsymbol{v}<em>{i})$在基$\boldsymbol{w}</em>{i}$下的坐标。</p>
<h3 id="特征向量与线性变换"><a href="#特征向量与线性变换" class="headerlink" title="特征向量与线性变换"></a>特征向量与线性变换</h3><p>如果线性变换$T$对应的矩阵$A$可对角化，那么有以下定理存在 </p>
<blockquote>
<p>定理：</p>
<p>如果矩阵$A$可以对角化，也就是$A &#x3D; X\Lambda X^{-1}$，并且$X$的列向量为$\boldsymbol{R}^{n}$的基，那么对于线性变换$T:\ \boldsymbol{R}^{n} \longrightarrow \boldsymbol{R}^{n}, \boldsymbol{u} \longmapsto A\boldsymbol{u}$，$\Lambda$为坐标转换矩阵。<br>由于$X\boldsymbol{c} &#x3D; \boldsymbol{u}$，因此<br>$$<br>X\boldsymbol{d} &#x3D; A\boldsymbol{u} &#x3D; AX\boldsymbol{c} &#x3D; X\Lambda X^{-1} X \boldsymbol{c} &#x3D; X\Lambda \boldsymbol{c}<br>$$<br>由此不难看出，$\Lambda \boldsymbol{c} &#x3D; \boldsymbol{d}$，也就是说$\Lambda$在此时起到了坐标转换矩阵的效果。</p>
</blockquote>
<p>不难看出，上式的证明并没有用到$\Lambda$为对角矩阵的条件，因此我们可以给出一个更强的定理 </p>
<blockquote>
<p>定理：</p>
<p>如果矩阵$A$与矩阵$C$相似，也就是$A &#x3D; PCP^{-1}$，并且$P$的列向量为$\boldsymbol{R}^{n}$的基，那么对于线性变换$T:\ \boldsymbol{R}^{n} \longrightarrow \boldsymbol{R}^{n}, \boldsymbol{u} \longmapsto A\boldsymbol{u}$，$C$为坐标转换矩阵。</p>
</blockquote>
<h3 id="奇异值分解与线性变换"><a href="#奇异值分解与线性变换" class="headerlink" title="奇异值分解与线性变换"></a>奇异值分解与线性变换</h3><p>由于$U$和$V$的列向量分别为$\boldsymbol{R}^{m}$和$\boldsymbol{R}^{n}$的基向量，因此有以下定理成立</p>
<blockquote>
<p>定理：</p>
<p>如果矩阵$A$可以进行奇异值分解，也就是$A &#x3D; U\Sigma V^{\mathrm{T}}$，那么对于线性变换$T:\ \boldsymbol{R}^{n} \longrightarrow \boldsymbol{R}^{m}, \boldsymbol{u} \longmapsto A\boldsymbol{u}$，$\Sigma$为坐标转换矩阵。</p>
</blockquote>
<blockquote>
<p>证明：</p>
<p>由于$\boldsymbol{u} &#x3D; \boldsymbol{u}<em>{\mathrm{c}} + \boldsymbol{u}</em>{\mathrm{ln}}$，因此$\boldsymbol{u} &#x3D; V_{r}\boldsymbol{c}<em>{\mathrm{c}} + V</em>{n - r}\boldsymbol{c}_{\mathrm{ln}} &#x3D; V\boldsymbol{c}$，从而<br>$$<br>U\boldsymbol{d} &#x3D; A\boldsymbol{u} &#x3D; AV\boldsymbol{c} &#x3D; U\Sigma V^{\mathrm{T}} V \boldsymbol{c} &#x3D; U\Sigma \boldsymbol{c}<br>$$<br>由此不难看出，$\Sigma \boldsymbol{c} &#x3D; \boldsymbol{d}$，也就是说$\Sigma$在此时起到了坐标转换矩阵的效果。</p>
</blockquote>
<h2 id="寻找合适的基"><a href="#寻找合适的基" class="headerlink" title="寻找合适的基"></a>寻找合适的基</h2><h3 id="摘要-23"><a href="#摘要-23" class="headerlink" title="摘要"></a>摘要</h3><ol>
<li>当$B_{\mathrm{in}}$和$B_{\mathrm{out}}$均为广义特征向量矩阵时，$A$变为Jordan标准型矩阵$J &#x3D; B^{-1}AB$</li>
</ol>
<h3 id="引入-9"><a href="#引入-9" class="headerlink" title="引入"></a>引入</h3><p>当$A$仅有$s$个特征向量时（$s &lt; n$），Jordan构造了额外的$n - s$个广义特征向量，从而使得Jordan标准型尽可能对角化。Jordan标准型满足：</p>
<ol>
<li><p>矩阵中有$s$个分块，这些分块沿着对角线分布</p>
</li>
<li><p>每个块有一个特征值$\lambda$，一个特征向量，以及在对角线上方有1</p>
</li>
</ol>
<h3 id="Jordan标准型"><a href="#Jordan标准型" class="headerlink" title="Jordan标准型"></a>Jordan标准型</h3><blockquote>
<p>定义：</p>
<p>当矩阵$A$有$s$个独立特征向量时，其与下面这种类型的矩阵相似<br>$$<br>J &#x3D; B^{-1}AB &#x3D;<br>\begin{bmatrix}<br>J_{1} &amp; &amp; \<br>&amp; \ddots &amp; \<br>&amp; &amp; J_{s} \<br>\end{bmatrix}<br>$$<br>其中，每一块都满足<br>$$<br>J_{i} &#x3D; \begin{bmatrix}<br>\lambda_{i} &amp; 1 &amp;  &amp;  \<br>&amp; \ddots &amp; \ddots &amp; \<br>&amp; &amp; \ddots &amp; 1 \<br>&amp; &amp; &amp; \lambda_{i} \<br>\end{bmatrix}<br>$$<br>我们将形如$J$的矩阵称为Jordan标准型矩阵</p>
</blockquote>
<p>注意，如果两个矩阵有相同的Jordan标准型，那么这两个矩阵相似。</p>
<h1 id="复向量和复矩阵"><a href="#复向量和复矩阵" class="headerlink" title="复向量和复矩阵"></a>复向量和复矩阵</h1><h2 id="本章总结"><a href="#本章总结" class="headerlink" title="本章总结"></a>本章总结</h2><ol>
<li><p>$\boldsymbol{R}^{n}$：有$n$个实参数的向量$\longleftrightarrow$$\boldsymbol{C}^{n}$：有$n$个复参数的向量</p>
</li>
<li><p>长度：$||\boldsymbol{x}||^{2} &#x3D; \sum\limits_{i &#x3D; 1}^{n} x_{i}^{n}$ $\longleftrightarrow$ 长度：$||\boldsymbol{x}||^{2} &#x3D; \sum\limits_{i &#x3D; 1}^{n} |z_{n}|^{2}$</p>
</li>
<li><p>转置：$(A^{\mathrm{T}})<em>{ij} &#x3D; A</em>{ji}$ $\longleftrightarrow$ 共轭转置：$(A^{\mathrm{H}})<em>{ij} &#x3D; \overline{A}</em>{ji}$</p>
</li>
<li><p>内积：$\boldsymbol{x}^{\mathrm{T}}\boldsymbol{y}$ $\longleftrightarrow$内积：$\boldsymbol{u}^{\mathrm{H}}\boldsymbol{v}$</p>
</li>
<li><p>正交性：$\boldsymbol{x}^{\mathrm{T}}\boldsymbol{y} &#x3D; 0$ $\longleftrightarrow$正交性：$\boldsymbol{u}^{\mathrm{H}}\boldsymbol{v} &#x3D; 0$</p>
</li>
<li><p>对称矩阵：$S &#x3D; S^{\mathrm{T}}$ $\longleftrightarrow$ Hermite矩阵：$S &#x3D; S^{\mathrm{H}}$</p>
</li>
<li><p>正交矩阵：$Q^{\mathrm{T}} &#x3D; Q^{-1}$ $\longleftrightarrow$ Unitary矩阵：$U^{\mathrm{H}} &#x3D; U^{-1}$</p>
</li>
<li><p>$S &#x3D; Q\Lambda Q^{\mathrm{T}}$（$\Lambda$为实矩阵） $\longleftrightarrow$ $S &#x3D; U\Lambda U^{\mathrm{H}}$（$\Lambda$为实矩阵）</p>
</li>
</ol>
<h2 id="Hermite矩阵"><a href="#Hermite矩阵" class="headerlink" title="Hermite矩阵"></a>Hermite矩阵</h2><p>以下是几条有关Hermite矩阵的性质：</p>
<ol>
<li><p>如果$S$为Hermite矩阵，而$\boldsymbol{z}$为任意的复向量，那么$\boldsymbol{z}^{\mathrm{H}}S\boldsymbol{z}$为实数</p>
</li>
<li><p>Hermite矩阵的特征值均为实数</p>
</li>
<li><p>Hermite矩阵的特征向量均正交</p>
</li>
</ol>

      
    </div>
    <footer class="article-footer">
      <a data-url="https://vasily-alexievich-korolev.github.io/2024/01/12/2024-01-12-Linear_Algebra/" data-id="clr9ll7fl0000ikth9hqj2t2j" data-title="2024-01-12-Linear_Algebra" class="article-share-link"><span class="fa fa-share">分享</span></a>
      
      
      
    </footer>
  </div>
  
    
<nav id="article-nav">
  
  
    <a href="/2024/01/12/hello-world/" id="article-nav-older" class="article-nav-link-wrap">
      <strong class="article-nav-caption">后一篇</strong>
      <div class="article-nav-title">Hello World</div>
    </a>
  
</nav>

  
</article>


</section>
        
          <aside id="sidebar">
  
    

  
    

  
    
  
    
  <div class="widget-wrap">
    <h3 class="widget-title">归档</h3>
    <div class="widget">
      <ul class="archive-list"><li class="archive-list-item"><a class="archive-list-link" href="/archives/2024/01/">一月 2024</a></li></ul>
    </div>
  </div>


  
    
  <div class="widget-wrap">
    <h3 class="widget-title">最新文章</h3>
    <div class="widget">
      <ul>
        
          <li>
            <a href="/2024/01/12/2024-01-12-Linear_Algebra/">2024-01-12-Linear_Algebra</a>
          </li>
        
          <li>
            <a href="/2024/01/12/hello-world/">Hello World</a>
          </li>
        
      </ul>
    </div>
  </div>

  
</aside>
        
      </div>
      <footer id="footer">
  
  <div class="outer">
    <div id="footer-info" class="inner">
      
      &copy; 2024 Vasily Alexievich Korolev<br>
      Powered by <a href="https://hexo.io/" target="_blank">Hexo</a>
    </div>
  </div>
</footer>

    </div>
    <nav id="mobile-nav">
  
    <a href="/" class="mobile-nav-link">Home</a>
  
    <a href="/archives" class="mobile-nav-link">Archives</a>
  
</nav>
    


<script src="/js/jquery-3.6.4.min.js"></script>



  
<script src="/fancybox/jquery.fancybox.min.js"></script>




<script src="/js/script.js"></script>





  </div>
</body>
</html>